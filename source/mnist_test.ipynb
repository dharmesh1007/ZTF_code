{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 - 8s - loss: 0.1952 - accuracy: 0.9405 - val_loss: 0.0961 - val_accuracy: 0.9702 - 8s/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "1500/1500 - 8s - loss: 0.0641 - accuracy: 0.9813 - val_loss: 0.0638 - val_accuracy: 0.9805 - 8s/epoch - 5ms/step\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 123\u001b[0m\n\u001b[1;32m    120\u001b[0m \tsummarize_performance(scores)\n\u001b[1;32m    122\u001b[0m \u001b[39m# entry point, run the test harness\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m run_test_harness()\n",
      "Cell \u001b[0;32mIn[4], line 116\u001b[0m, in \u001b[0;36mrun_test_harness\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m trainX, testX \u001b[39m=\u001b[39m prep_pixels(trainX, testX)\n\u001b[1;32m    115\u001b[0m \u001b[39m# evaluate model\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m scores, histories \u001b[39m=\u001b[39m evaluate_model(trainX, trainY)\n\u001b[1;32m    117\u001b[0m \u001b[39m# learning curves\u001b[39;00m\n\u001b[1;32m    118\u001b[0m summarize_diagnostics(histories)\n",
      "Cell \u001b[0;32mIn[4], line 77\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(dataX, dataY, n_folds)\u001b[0m\n\u001b[1;32m     75\u001b[0m trainX, trainY, testX, testY \u001b[39m=\u001b[39m dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n\u001b[1;32m     76\u001b[0m \u001b[39m# fit model\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(trainX, trainY, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(testX, testY), verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     78\u001b[0m \u001b[39m# evaluate model\u001b[39;00m\n\u001b[1;32m     79\u001b[0m _, acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(testX, testY, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tfenv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tfenv/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tfenv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tfenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tfenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tfenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tfenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tfenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tfenv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tfenv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels(trainX, testX)\n",
    "    # evaluate model\n",
    "    scores, histories = evaluate_model(trainX, trainY)\n",
    "    # learning curves\n",
    "    summarize_diagnostics(histories)\n",
    "    # summarize estimated performance\n",
    "    summarize_performance(scores)\n",
    "\n",
    "# baseline cnn model for mnist\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "\t# reshape dataset to have a single channel\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# evaluate a model using k-fold cross-validation\n",
    "def evaluate_model(dataX, dataY, n_folds=5):\n",
    "\tscores, histories = list(), list()\n",
    "\t# prepare cross validation\n",
    "\tkfold = KFold(n_folds, shuffle=True, random_state=1)\n",
    "\t# enumerate splits\n",
    "\tfor train_ix, test_ix in kfold.split(dataX):\n",
    "\t\t# define model\n",
    "\t\tmodel = define_model()\n",
    "\t\t# select rows for train and test\n",
    "\t\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
    "\t\t# fit model\n",
    "\t\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=2)\n",
    "\t\t# evaluate model\n",
    "\t\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\t\tprint('> %.3f' % (acc * 100.0))\n",
    "\t\t# stores scores\n",
    "\t\tscores.append(acc)\n",
    "\t\thistories.append(history)\n",
    "\treturn scores, histories\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(histories):\n",
    "\tfor i in range(len(histories)):\n",
    "\t\t# plot loss\n",
    "\t\tplt.subplot(2, 1, 1)\n",
    "\t\tplt.title('Cross Entropy Loss')\n",
    "\t\tplt.plot(histories[i].history['loss'], color='blue', label='train')\n",
    "\t\tplt.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
    "\t\t# plot accuracy\n",
    "\t\tplt.subplot(2, 1, 2)\n",
    "\t\tplt.title('Classification Accuracy')\n",
    "\t\tplt.plot(histories[i].history['accuracy'], color='blue', label='train')\n",
    "\t\tplt.plot(histories[i].history['val_accuracy'], color='orange', label='test')\n",
    "\tplt.show()\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_performance(scores):\n",
    "\t# print summary\n",
    "\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n",
    "\t# box and whisker plots of results\n",
    "\tplt.boxplot(scores)\n",
    "\tplt.show()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# evaluate model\n",
    "\tscores, histories = evaluate_model(trainX, trainY)\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(histories)\n",
    "\t# summarize estimated performance\n",
    "\tsummarize_performance(scores)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dwarf_nova_SU_UMa    630\n",
      "dwarf_nova_Z_Cam     174\n",
      "nova_like            144\n",
      "nova_like_VY_Scl     120\n",
      "dwarf_nova_U_Gem     116\n",
      "polar                114\n",
      "int_polar             49\n",
      "AMCVn                 46\n",
      "nova                  46\n",
      "Name: labels_2, dtype: int64\n",
      "(1439, 270)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from lcfunctions import load_lasair_lc, lasair_clean\n",
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "label_scheme = 'labels_2'\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "dataset = pd.read_csv(f'../processed_data/dataset_allfeatures_inc_labels.csv', low_memory=False)\n",
    "dataset = dataset[dataset[label_scheme].notna()].reset_index(drop=True)\n",
    "print(dataset[label_scheme].value_counts())\n",
    "print(dataset.shape)\n",
    "\n",
    "folderpath = '../lightcurves_dataset/lasair_2023_03_25'\n",
    "\n",
    "# Create an empty 3D numpy array\n",
    "length = 500\n",
    "length_int = 1000\n",
    "limit = 100\n",
    "a = 10\n",
    "bins = limit*a\n",
    "max_n_obs = 0\n",
    "len_vals_g = []\n",
    "len_vals_r = []\n",
    "\n",
    "allgdmdt = np.empty((0,))\n",
    "allrdmdt = np.empty((0,))\n",
    "\n",
    "X_g = np.empty((0, length)) # g band\n",
    "X_g_int = np.empty((0, length_int)) # g band interpolated\n",
    "X_gdmdt = np.empty((0, length)) # g band dm/dt\n",
    "X_gjd = np.empty((0, length, 2)) # g band with julian dates\n",
    "X_gdt = np.empty((0, length, 2)) # g band with time differences\n",
    "X_gdmdt2 = np.empty((0, length, 2)) # g band with dm/dt and time differences\n",
    "X_ghist = np.empty((0, bins)) # g band histogram\n",
    "\n",
    "# As above but for r band\n",
    "X_r = np.empty((0, length))\n",
    "X_r_int = np.empty((0, length_int))\n",
    "X_rdmdt = np.empty((0, length))\n",
    "X_rjd = np.empty((0, length, 2))\n",
    "X_rdt = np.empty((0, length, 2))\n",
    "X_rdmdt2 = np.empty((0, length, 2))\n",
    "X_rhist = np.empty((0, bins))\n",
    "\n",
    "for obj in dataset['oid_ztf'].to_list():\n",
    "    # Load and process lasair light curve\n",
    "    lc_test = load_lasair_lc(oid=obj, path=folderpath)\n",
    "    lc_appmag_test = lasair_clean(lc_test, limit=25, magerrlim=1)\n",
    "\n",
    "    # Create a copy of the light curve\n",
    "    df_lc = lc_appmag_test.copy()\n",
    "\n",
    "    # Split the light curve into g and r bands\n",
    "    df_lc_g = df_lc[df_lc['fid'] == 1].reset_index(drop=True)\n",
    "    df_lc_r = df_lc[df_lc['fid'] == 2].reset_index(drop=True)\n",
    "\n",
    "    # Get the mags and times\n",
    "    lc_g = df_lc_g['dc_mag'].values\n",
    "    lc_r = df_lc_r['dc_mag'].values\n",
    "    try:\n",
    "        lc_g_jd = (df_lc_g['jd'] - df_lc_g['jd'][0]).values\n",
    "    except:\n",
    "        lc_g_jd = []\n",
    "    try:\n",
    "        lc_r_jd = (df_lc_r['jd'] - df_lc_r['jd'][0]).values\n",
    "    except:\n",
    "        lc_r_jd = []\n",
    "\n",
    "\n",
    "    # Interpolate the light curve to 1 day cadence or a set number of points\n",
    "    try:\n",
    "        lc_g_int = np.interp(np.arange(0, lc_g_jd[-1], 1), lc_g_jd, lc_g)\n",
    "        lc_g_int = np.interp(np.arange(0,length_int,1), lc_g_jd, lc_g)\n",
    "        # print(lc_g_int.shape)\n",
    "    except:\n",
    "        lc_g_int = np.array([])\n",
    "    try:\n",
    "        lc_r_int = np.interp(np.arange(0, lc_r_jd[-1], 1), lc_r_jd, lc_r)\n",
    "        lc_r_int = np.interp(np.arange(0,length_int,1), lc_r_jd, lc_r)\n",
    "    except:\n",
    "        lc_r_int = np.array([])\n",
    "    \n",
    "    # Time differences between observations and prepend a zero to the array because the first observation has no time difference\n",
    "    if len(lc_g_jd) > 0:\n",
    "        lc_g_dt = np.diff(lc_g_jd)\n",
    "        lc_g_dt = np.insert(lc_g_dt, 0, 0)\n",
    "    else:\n",
    "        lc_g_dt = np.array([])\n",
    "    \n",
    "    if len(lc_r_jd) > 0:\n",
    "        lc_r_dt = np.diff(lc_r_jd)\n",
    "        lc_r_dt = np.insert(lc_r_dt, 0, 0)\n",
    "    else:\n",
    "        lc_r_dt = np.array([])\n",
    "\n",
    "    # Magnitude changes between observations and prepend a zero to the array because the first observation has no magnitude change\n",
    "    if len(lc_g) > 0:\n",
    "        lc_g_dm = np.diff(lc_g)\n",
    "        lc_g_dm = np.insert(lc_g_dm, 0, 0)\n",
    "    else:\n",
    "        lc_g_dm = np.array([])\n",
    "    if len(lc_r) > 0:\n",
    "        lc_r_dm = np.diff(lc_r)\n",
    "        lc_r_dm = np.insert(lc_r_dm, 0, 0)\n",
    "    else:\n",
    "        lc_r_dm = np.array([])\n",
    "\n",
    "    # Get dm/dt and replace nan values with 0\n",
    "    lc_g_dmdt = lc_g_dm / lc_g_dt\n",
    "    lc_g_dmdt = np.nan_to_num(lc_g_dmdt, nan=0)\n",
    "    lc_r_dmdt = lc_r_dm / lc_r_dt\n",
    "    lc_r_dmdt = np.nan_to_num(lc_r_dmdt, nan=0)\n",
    "\n",
    "    # Create a histogram of the magnitude derivatives\n",
    "    lc_g_dmdt_cpy = lc_g_dmdt.copy()\n",
    "    lc_r_dmdt_cpy = lc_r_dmdt.copy()\n",
    "    # if value is greater than 50 or less than -50, set to 50 or -50 respectively\n",
    "    lc_g_dmdt_cpy[lc_g_dmdt_cpy > limit] = limit\n",
    "    lc_g_dmdt_cpy[lc_g_dmdt_cpy < -limit] = -limit\n",
    "    lc_r_dmdt_cpy[lc_r_dmdt_cpy > limit] = limit\n",
    "    lc_r_dmdt_cpy[lc_r_dmdt_cpy < -limit] = -limit\n",
    "    lc_g_hist, lc_g_bins = np.histogram(lc_g_dmdt_cpy, bins=np.linspace(-limit, limit, bins+1))\n",
    "    lc_r_hist, lc_r_bins = np.histogram(lc_r_dmdt_cpy, bins=np.linspace(-limit, limit, bins+1))\n",
    "    # print(lc_g_bins, lc_r_bins.shape)\n",
    "    # print(max(lc_g_hist))\n",
    "\n",
    "    # Add the dm/dt to the array\n",
    "    allgdmdt = np.append(allgdmdt, lc_g_dmdt, axis=0)\n",
    "    allrdmdt = np.append(allrdmdt, lc_r_dmdt, axis=0)\n",
    "\n",
    "    if len(lc_g) | len(lc_r) > max_n_obs:\n",
    "        max_n_obs = max(len(lc_g), len(lc_r))\n",
    "    \n",
    "    len_vals_g.append(len(lc_g))\n",
    "    len_vals_r.append(len(lc_r))\n",
    "\n",
    "    # Make the array of length length, backfilling with zeros\n",
    "    if len(lc_g) < length:\n",
    "        lc_g = np.pad(lc_g, (length - len(lc_g), 0), 'constant', constant_values=(0, 0))\n",
    "        lc_g_dm = np.pad(lc_g_dm, (length - len(lc_g_dm), 0), 'constant', constant_values=(0, 0))\n",
    "        lc_g_dmdt = np.pad(lc_g_dmdt, (length - len(lc_g_dmdt), 0), 'constant', constant_values=(0, 0))\n",
    "        lc_g_dt = np.pad(lc_g_dt, (length - len(lc_g_dt), 0), 'constant', constant_values=(0, 0))\n",
    "        lc_g_jd = np.pad(lc_g_jd, (length - len(lc_g_jd), 0), 'constant', constant_values=(0, 0))\n",
    "    elif len(lc_g) >= length:\n",
    "        lc_g = lc_g[-length:]\n",
    "        lc_g_dm = lc_g_dm[-length:]\n",
    "        lc_g_dmdt = lc_g_dmdt[-length:]\n",
    "        lc_g_dt = lc_g_dt[-length:]\n",
    "        lc_g_jd = lc_g_jd[-length:]\n",
    "    if len(lc_r) < length:\n",
    "        lc_r = np.pad(lc_r, (length - len(lc_r), 0), 'constant', constant_values=(0, 0))\n",
    "        lc_r_dm = np.pad(lc_r_dm, (length - len(lc_r_dm), 0), 'constant', constant_values=(0, 0))\n",
    "        lc_r_dmdt = np.pad(lc_r_dmdt, (length - len(lc_r_dmdt), 0), 'constant', constant_values=(0, 0))\n",
    "        lc_r_dt = np.pad(lc_r_dt, (length - len(lc_r_dt), 0), 'constant', constant_values=(0, 0))\n",
    "        lc_r_jd = np.pad(lc_r_jd, (length - len(lc_r_jd), 0), 'constant', constant_values=(0, 0))\n",
    "    elif len(lc_r) >= length:\n",
    "        lc_r = lc_r[-length:]\n",
    "        lc_r_dm = lc_r_dm[-length:]\n",
    "        lc_r_dmdt = lc_r_dmdt[-length:]\n",
    "        lc_r_dt = lc_r_dt[-length:]\n",
    "        lc_r_jd = lc_r_jd[-length:]\n",
    "\n",
    "    # Make the array of length length_int, backfilling with zeros\n",
    "    if len(lc_g_int) < length_int:\n",
    "        lc_g_int = np.pad(lc_g_int, (length_int - len(lc_g_int), 0), 'constant', constant_values=(0, 0))\n",
    "    elif len(lc_g_int) >= length_int:\n",
    "        lc_g_int = lc_g_int[-length_int:]\n",
    "    if len(lc_r_int) < length_int:\n",
    "        lc_r_int = np.pad(lc_r_int, (length_int - len(lc_r_int), 0), 'constant', constant_values=(0, 0))\n",
    "    elif len(lc_r_int) >= length_int:\n",
    "        lc_r_int = lc_r_int[-length_int:]\n",
    "\n",
    "    \n",
    "    # Add the light curve to the array\n",
    "    X_g = np.append(X_g, [lc_g], axis=0)\n",
    "    X_g_int = np.append(X_g_int, [lc_g_int], axis=0)\n",
    "    X_gdmdt = np.append(X_gdmdt, [lc_g_dmdt], axis=0)\n",
    "    X_gjd = np.append(X_gjd, [np.stack((lc_g, lc_g_jd), axis=1)], axis=0)\n",
    "    X_gdt = np.append(X_gdt, [np.stack((lc_g, lc_g_dt), axis=1)], axis=0)\n",
    "    X_gdmdt2 = np.append(X_gdmdt2, [np.stack((lc_g_dm, lc_g_dt), axis=1)], axis=0)\n",
    "    X_ghist = np.append(X_ghist, [lc_g_hist], axis=0)\n",
    "    \n",
    "    X_r = np.append(X_r, [lc_r], axis=0)\n",
    "    X_r_int = np.append(X_r_int, [lc_r_int], axis=0)\n",
    "    X_rdmdt = np.append(X_rdmdt, [lc_r_dmdt], axis=0)\n",
    "    X_rjd = np.append(X_rjd, [np.stack((lc_r, lc_r_jd), axis=1)], axis=0)\n",
    "    X_rdt = np.append(X_rdt, [np.stack((lc_r, lc_r_dt), axis=1)], axis=0)\n",
    "    X_rdmdt2 = np.append(X_rdmdt2, [np.stack((lc_r_dm, lc_r_dt), axis=1)], axis=0)\n",
    "    X_rhist = np.append(X_rhist, [lc_r_hist], axis=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [ 0.00000000e+00],\n",
       "       [-1.70130650e+01],\n",
       "       [-1.79108690e+01],\n",
       "       [-1.69133160e+01],\n",
       "       [-1.78954434e+01],\n",
       "       [-1.75848259e+01],\n",
       "       [-1.66168582e+01],\n",
       "       [-2.04503628e+01],\n",
       "       [-2.02026403e+01],\n",
       "       [-1.97849831e+01],\n",
       "       [-2.06010086e+01],\n",
       "       [-1.66099651e+01],\n",
       "       [-1.75234029e+01],\n",
       "       [-1.76604710e+01],\n",
       "       [-1.76703409e+01],\n",
       "       [-1.75524328e+01],\n",
       "       [-1.66733827e+01],\n",
       "       [-1.67429585e+01],\n",
       "       [-1.66703295e+01],\n",
       "       [-1.75174893e+01],\n",
       "       [-1.64141407e+01],\n",
       "       [-1.68849408e+01],\n",
       "       [-1.67999114e+01],\n",
       "       [-1.65140895e+01],\n",
       "       [-1.64027100e+01],\n",
       "       [-1.63215699e+01],\n",
       "       [-1.64840866e+01],\n",
       "       [-1.64481868e+01],\n",
       "       [-1.67394075e+01],\n",
       "       [-1.69292655e+01],\n",
       "       [-1.68754658e+01],\n",
       "       [-1.64331635e+01],\n",
       "       [-1.66766846e+01],\n",
       "       [-1.65462149e+01],\n",
       "       [-1.61362903e+01],\n",
       "       [-1.66177853e+01],\n",
       "       [-1.68991721e+01],\n",
       "       [-1.62358296e+01],\n",
       "       [-1.65794362e+01],\n",
       "       [-1.69602739e+01],\n",
       "       [-1.67535067e+01],\n",
       "       [-1.61136117e+01],\n",
       "       [-1.67421222e+01],\n",
       "       [-1.63063516e+01],\n",
       "       [-1.65875044e+01],\n",
       "       [-1.65470605e+01],\n",
       "       [-1.65748928e+01],\n",
       "       [-1.67236803e+01],\n",
       "       [-1.65984923e+01],\n",
       "       [-1.66734259e+01],\n",
       "       [-1.61243886e+01],\n",
       "       [-1.63808120e+01],\n",
       "       [-1.65327913e+01],\n",
       "       [-1.68801778e+01],\n",
       "       [-1.76181480e+01],\n",
       "       [-1.76552950e+01],\n",
       "       [-1.76454665e+01],\n",
       "       [-1.68769986e+01],\n",
       "       [-1.69403068e+01],\n",
       "       [-1.76305940e+01],\n",
       "       [-1.68955919e+01],\n",
       "       [-1.68325798e+01],\n",
       "       [-1.69470088e+01],\n",
       "       [-1.63817218e+01],\n",
       "       [-1.68084435e+01],\n",
       "       [-1.63772243e+01],\n",
       "       [-1.69554280e+01],\n",
       "       [-1.69774538e+01],\n",
       "       [-1.76875283e+01],\n",
       "       [-1.65373678e+01],\n",
       "       [-1.63226935e+01],\n",
       "       [-1.68563077e+01],\n",
       "       [-1.69569254e+01],\n",
       "       [-1.69185209e+01],\n",
       "       [-1.64397710e+01],\n",
       "       [-1.70821693e+01],\n",
       "       [-1.66416721e+01],\n",
       "       [-1.68373036e+01],\n",
       "       [-1.67061545e+01],\n",
       "       [-1.66966065e+01],\n",
       "       [-1.67675974e+01],\n",
       "       [-1.66896355e+01],\n",
       "       [-1.66053734e+01],\n",
       "       [-1.79555802e+01],\n",
       "       [-1.69108545e+01],\n",
       "       [-1.67568711e+01],\n",
       "       [-4.73877406e-01],\n",
       "       [-8.68892336e-01],\n",
       "       [ 7.87085269e-01],\n",
       "       [-5.27664741e-01],\n",
       "       [ 6.63773684e-01],\n",
       "       [-4.38903395e-01],\n",
       "       [ 3.99941345e-01],\n",
       "       [-9.89763528e-01],\n",
       "       [-1.46617973e-01],\n",
       "       [-8.00004794e-01],\n",
       "       [-4.28113401e-01],\n",
       "       [-3.33758679e-01],\n",
       "       [-1.75435613e+00],\n",
       "       [-4.76680263e-01],\n",
       "       [-1.82360631e+00],\n",
       "       [-6.66006870e-01],\n",
       "       [-2.33720159e+00],\n",
       "       [-3.90342056e-01],\n",
       "       [-2.16350235e+00],\n",
       "       [-8.48484485e-01],\n",
       "       [-8.51866884e-01],\n",
       "       [-1.38639359e+00],\n",
       "       [-1.52076777e+00],\n",
       "       [-1.55658775e+00],\n",
       "       [-6.70606602e-01],\n",
       "       [-1.41480761e+00],\n",
       "       [-1.42286488e+00],\n",
       "       [-2.20393718e+00],\n",
       "       [-1.06685468e+00],\n",
       "       [-1.39501274e+00],\n",
       "       [-1.22554866e-01],\n",
       "       [-2.08128891e+00],\n",
       "       [-7.86287936e-01],\n",
       "       [-2.17841056e+00],\n",
       "       [-1.09533830e+00],\n",
       "       [-2.27409768e+00],\n",
       "       [-2.42690597e+00],\n",
       "       [-1.01312496e+00],\n",
       "       [-6.01046732e-01],\n",
       "       [-1.11384438e+00],\n",
       "       [-7.85026888e-01],\n",
       "       [-3.62647555e-01],\n",
       "       [-1.55187521e-01],\n",
       "       [-1.55173694e-01],\n",
       "       [-7.25633603e-01],\n",
       "       [-1.90280085e+00],\n",
       "       [-7.32271423e-02],\n",
       "       [-5.60873376e-01],\n",
       "       [-1.70536668e+00],\n",
       "       [-1.76042826e-01],\n",
       "       [-1.64277292e+00],\n",
       "       [ 1.26912654e-01],\n",
       "       [-2.11343963e+00],\n",
       "       [-2.07670169e+00],\n",
       "       [-2.13591825e+00],\n",
       "       [-1.67346867e+00],\n",
       "       [-1.65018960e+00],\n",
       "       [-1.23017144e+00],\n",
       "       [-1.46602277e+00],\n",
       "       [-1.19543809e+00],\n",
       "       [-1.72908755e+00],\n",
       "       [-4.00453846e-01],\n",
       "       [-1.48211831e+00],\n",
       "       [-7.79323542e-01],\n",
       "       [-4.07017066e-01],\n",
       "       [ 8.14970318e-02],\n",
       "       [-7.35738971e-01],\n",
       "       [-1.32812602e+00],\n",
       "       [-4.41570993e-01],\n",
       "       [-9.27303602e-01],\n",
       "       [-1.55446534e+00],\n",
       "       [-2.08693873e-01],\n",
       "       [-6.23751956e-01],\n",
       "       [-2.41224204e-01],\n",
       "       [-5.37793679e-01],\n",
       "       [-1.14830916e+00],\n",
       "       [-1.02082023e+00],\n",
       "       [-1.23112159e+00],\n",
       "       [-3.04069348e-01],\n",
       "       [-1.76286722e+00],\n",
       "       [-9.49844565e-01],\n",
       "       [-2.82479749e-01],\n",
       "       [-5.11429478e-01],\n",
       "       [-1.33344822e+00],\n",
       "       [ 3.45366746e-02],\n",
       "       [ 1.90151110e-01],\n",
       "       [-2.12846179e-01],\n",
       "       [ 8.40885174e-01],\n",
       "       [ 8.50413225e-01],\n",
       "       [ 8.09548178e-01],\n",
       "       [ 1.70866744e+00],\n",
       "       [ 7.48370595e-01],\n",
       "       [ 3.70982643e-01],\n",
       "       [ 1.81096340e+00],\n",
       "       [ 4.58123800e-02],\n",
       "       [ 4.55472541e-03],\n",
       "       [ 1.30223952e+00],\n",
       "       [ 4.00815165e-02],\n",
       "       [ 9.07823985e-01],\n",
       "       [ 6.44603855e-01],\n",
       "       [ 1.13623010e-01],\n",
       "       [ 1.22197355e+00],\n",
       "       [-1.01183344e+00],\n",
       "       [ 1.98896499e-01],\n",
       "       [ 1.08694066e+00],\n",
       "       [ 6.73671576e-02],\n",
       "       [ 1.23491510e+00],\n",
       "       [ 1.06968127e+00],\n",
       "       [-2.79959731e-01],\n",
       "       [ 4.75522214e-01],\n",
       "       [ 1.37169161e+00],\n",
       "       [-2.10211414e-01],\n",
       "       [ 5.89889525e-02],\n",
       "       [ 4.10537369e-01],\n",
       "       [ 4.49924604e-01],\n",
       "       [ 6.08073458e-01],\n",
       "       [-8.46841295e-02],\n",
       "       [ 1.52040463e+00],\n",
       "       [ 1.00129449e+00],\n",
       "       [ 1.34064601e-01],\n",
       "       [-3.32116074e-01],\n",
       "       [ 2.85139984e-01],\n",
       "       [ 1.42372158e+00],\n",
       "       [ 1.16570522e+00],\n",
       "       [ 8.72548462e-01],\n",
       "       [ 1.03724663e+00],\n",
       "       [ 1.49853187e-01],\n",
       "       [ 2.88102572e-01],\n",
       "       [ 1.05263194e+00],\n",
       "       [ 1.38266750e+00],\n",
       "       [ 6.25384846e-01],\n",
       "       [ 3.93671442e-01],\n",
       "       [ 5.03224218e-01],\n",
       "       [ 8.44114621e-01],\n",
       "       [ 1.17406201e+00],\n",
       "       [ 1.80944389e+00],\n",
       "       [ 1.33641101e+00],\n",
       "       [ 1.40212655e-01],\n",
       "       [ 5.47458462e-01],\n",
       "       [ 5.11747208e-01],\n",
       "       [ 4.61646766e-01],\n",
       "       [ 5.90936916e-01],\n",
       "       [ 9.93288953e-01],\n",
       "       [ 5.93565387e-01],\n",
       "       [ 2.19042179e-01],\n",
       "       [ 5.60956333e-01],\n",
       "       [-2.09880660e-01],\n",
       "       [ 1.77078982e+00],\n",
       "       [ 8.97457110e-01],\n",
       "       [ 3.83116223e-01],\n",
       "       [ 8.32262082e-01],\n",
       "       [ 1.21809203e-01],\n",
       "       [ 7.28838759e-01],\n",
       "       [ 1.02472329e+00],\n",
       "       [ 1.71222218e-01],\n",
       "       [ 3.87693591e-01],\n",
       "       [ 7.22932216e-01],\n",
       "       [ 9.01657718e-01],\n",
       "       [ 1.23703713e+00],\n",
       "       [ 1.24562640e+00],\n",
       "       [ 5.50121449e-01],\n",
       "       [ 8.75900173e-01],\n",
       "       [ 3.83757233e-01],\n",
       "       [ 3.16210003e-01],\n",
       "       [ 7.98302366e-01],\n",
       "       [ 4.19161342e-01],\n",
       "       [ 1.01148399e+00],\n",
       "       [ 1.75884911e+00],\n",
       "       [ 6.69434588e-01],\n",
       "       [ 6.39660834e-01],\n",
       "       [ 1.07294358e+00],\n",
       "       [ 1.02375926e+00],\n",
       "       [ 1.27789253e+00],\n",
       "       [ 8.83638251e-01],\n",
       "       [ 6.91867855e-01],\n",
       "       [ 1.42884514e+00],\n",
       "       [ 2.18817884e+00],\n",
       "       [ 9.71208038e-01],\n",
       "       [ 9.23543382e-01],\n",
       "       [ 6.68165688e-01],\n",
       "       [ 1.10335372e+00],\n",
       "       [ 1.19027857e+00],\n",
       "       [ 1.72215840e+00],\n",
       "       [ 2.04871961e+00],\n",
       "       [ 9.48681105e-01],\n",
       "       [ 5.25568405e-01],\n",
       "       [ 1.91599058e+00],\n",
       "       [ 1.64265706e+00],\n",
       "       [ 2.01495931e+00],\n",
       "       [ 1.08957082e+00],\n",
       "       [ 1.55530226e+00],\n",
       "       [ 1.68943704e+00],\n",
       "       [ 1.33750341e+00],\n",
       "       [ 1.00922740e+00],\n",
       "       [ 1.95386409e+00],\n",
       "       [ 6.85591063e-01],\n",
       "       [ 1.76835139e-01],\n",
       "       [ 4.97925006e-01],\n",
       "       [ 1.08986393e+00],\n",
       "       [ 1.71595591e+00],\n",
       "       [ 6.16917178e-01],\n",
       "       [ 1.25241235e+00],\n",
       "       [ 6.98151861e-01],\n",
       "       [ 6.31775269e-01],\n",
       "       [ 1.18030421e+00],\n",
       "       [ 7.52137032e-01],\n",
       "       [ 1.08165676e+00],\n",
       "       [ 1.45729630e+00],\n",
       "       [-2.79058996e-01],\n",
       "       [ 1.21495039e+00],\n",
       "       [-2.52696808e-01],\n",
       "       [-6.84663946e-01],\n",
       "       [ 3.09871545e-01],\n",
       "       [ 1.10303180e+00],\n",
       "       [ 1.73583602e+00],\n",
       "       [ 1.26929830e+00],\n",
       "       [ 1.51652451e+00],\n",
       "       [ 8.23534651e-01],\n",
       "       [ 3.46405601e-02],\n",
       "       [-4.34891515e-01],\n",
       "       [-2.09329175e-01],\n",
       "       [-1.80102940e-01],\n",
       "       [ 7.39348869e-01],\n",
       "       [ 4.08803508e-01],\n",
       "       [ 7.49626553e-01],\n",
       "       [ 5.58004354e-01],\n",
       "       [ 4.42677459e-01],\n",
       "       [ 7.19378280e-01],\n",
       "       [ 1.49690639e+00],\n",
       "       [ 1.61289879e+00],\n",
       "       [ 1.35520889e+00],\n",
       "       [-3.47012806e-01],\n",
       "       [-4.23530715e-01],\n",
       "       [-2.74073139e-01],\n",
       "       [-1.17375993e-01],\n",
       "       [ 6.44070451e-01],\n",
       "       [ 3.34798509e-01],\n",
       "       [ 1.05010575e+00],\n",
       "       [ 5.24849018e-01],\n",
       "       [ 7.58614410e-01],\n",
       "       [ 7.18593164e-01],\n",
       "       [ 1.65911690e-01],\n",
       "       [ 6.63714311e-01],\n",
       "       [ 1.25391959e+00],\n",
       "       [ 6.86807830e-01],\n",
       "       [ 1.03710617e+00],\n",
       "       [ 4.27866034e-01],\n",
       "       [ 1.02842156e+00],\n",
       "       [ 9.34659684e-01],\n",
       "       [ 6.00150074e-01],\n",
       "       [ 3.36463962e-02],\n",
       "       [ 3.11614398e-01],\n",
       "       [ 3.28876292e-02],\n",
       "       [ 6.89274632e-02],\n",
       "       [ 7.88991760e-01],\n",
       "       [ 6.11504196e-01],\n",
       "       [ 7.28922591e-01],\n",
       "       [ 1.52401213e-01],\n",
       "       [ 6.18920803e-01],\n",
       "       [ 7.51086332e-01],\n",
       "       [ 4.29856868e-01],\n",
       "       [ 1.02192799e+00],\n",
       "       [-4.28885214e-01],\n",
       "       [ 1.03631863e-01],\n",
       "       [ 1.59315965e-01],\n",
       "       [ 2.00018221e-01],\n",
       "       [ 4.08411193e-01],\n",
       "       [ 1.16227432e+00],\n",
       "       [ 7.12242107e-01],\n",
       "       [ 7.32309120e-01],\n",
       "       [ 7.70196111e-01],\n",
       "       [-1.52343902e-01],\n",
       "       [-4.22415605e-01],\n",
       "       [ 7.55057888e-01],\n",
       "       [ 1.35734516e+00],\n",
       "       [ 1.20120530e+00],\n",
       "       [ 8.26371175e-01],\n",
       "       [ 1.03706321e+00],\n",
       "       [ 7.14891259e-01],\n",
       "       [ 1.13268548e-01],\n",
       "       [ 7.36442619e-01],\n",
       "       [ 9.04581220e-03],\n",
       "       [ 1.94254355e-01],\n",
       "       [ 3.80207371e-01],\n",
       "       [ 4.14499940e-01],\n",
       "       [ 6.52808572e-01],\n",
       "       [ 4.12221802e-02],\n",
       "       [-1.16229699e-02],\n",
       "       [ 4.13161129e-01],\n",
       "       [ 4.31030099e-01],\n",
       "       [ 1.10113716e-01],\n",
       "       [ 2.16949464e-01],\n",
       "       [ 6.75510011e-01],\n",
       "       [ 1.35292410e-01],\n",
       "       [ 3.28163076e-01]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I want a multi-channel input with the following:\n",
    "# 1. g band\n",
    "# 2. r band\n",
    "# Here is the new array using X_g and X_r\n",
    "X_g_new = np.reshape(X_g, (X_g.shape[0], X_g.shape[1], 1))\n",
    "X_r_new = np.reshape(X_r, (X_r.shape[0], X_r.shape[1], 1))\n",
    "X_new = np.concatenate((X_g_new, X_r_new), axis=2)\n",
    "\n",
    "# Now I want to a single channel but the colour. This would be X_g - X_r.\n",
    "X_gmr = X_g - X_r\n",
    "X_gmr_new = np.reshape(X_gmr, (X_gmr.shape[0], X_gmr.shape[1], 1))\n",
    "X_gmr_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1007, 1000, 1) (1007, 9) (432, 1000, 1) (432, 9)\n",
      "Epoch 1/150\n",
      "32/32 - 1s - loss: 2.1865 - categorical_accuracy: 0.2175 - val_loss: 2.0121 - val_categorical_accuracy: 0.4144 - 1s/epoch - 33ms/step\n",
      "Epoch 2/150\n",
      "32/32 - 1s - loss: 2.0496 - categorical_accuracy: 0.2592 - val_loss: 1.7974 - val_categorical_accuracy: 0.4838 - 523ms/epoch - 16ms/step\n",
      "Epoch 3/150\n",
      "32/32 - 1s - loss: 1.9344 - categorical_accuracy: 0.2602 - val_loss: 1.8903 - val_categorical_accuracy: 0.1782 - 505ms/epoch - 16ms/step\n",
      "Epoch 4/150\n",
      "32/32 - 1s - loss: 1.8697 - categorical_accuracy: 0.2413 - val_loss: 1.7553 - val_categorical_accuracy: 0.3102 - 567ms/epoch - 18ms/step\n",
      "Epoch 5/150\n",
      "32/32 - 1s - loss: 1.7974 - categorical_accuracy: 0.2721 - val_loss: 1.7554 - val_categorical_accuracy: 0.3056 - 558ms/epoch - 17ms/step\n",
      "Epoch 6/150\n",
      "32/32 - 1s - loss: 1.7292 - categorical_accuracy: 0.3426 - val_loss: 1.8625 - val_categorical_accuracy: 0.2130 - 546ms/epoch - 17ms/step\n",
      "Epoch 7/150\n",
      "32/32 - 1s - loss: 1.6672 - categorical_accuracy: 0.3426 - val_loss: 1.8452 - val_categorical_accuracy: 0.2454 - 521ms/epoch - 16ms/step\n",
      "Epoch 8/150\n",
      "32/32 - 1s - loss: 1.6229 - categorical_accuracy: 0.3684 - val_loss: 1.7293 - val_categorical_accuracy: 0.3125 - 513ms/epoch - 16ms/step\n",
      "Epoch 9/150\n",
      "32/32 - 1s - loss: 1.5952 - categorical_accuracy: 0.3734 - val_loss: 1.7021 - val_categorical_accuracy: 0.3611 - 545ms/epoch - 17ms/step\n",
      "Epoch 10/150\n",
      "32/32 - 1s - loss: 1.5637 - categorical_accuracy: 0.3972 - val_loss: 1.7492 - val_categorical_accuracy: 0.3218 - 517ms/epoch - 16ms/step\n",
      "Epoch 11/150\n",
      "32/32 - 1s - loss: 1.5235 - categorical_accuracy: 0.4389 - val_loss: 1.9020 - val_categorical_accuracy: 0.3102 - 532ms/epoch - 17ms/step\n",
      "Epoch 12/150\n",
      "32/32 - 1s - loss: 1.5550 - categorical_accuracy: 0.3932 - val_loss: 1.9563 - val_categorical_accuracy: 0.2199 - 526ms/epoch - 16ms/step\n",
      "Epoch 13/150\n",
      "32/32 - 1s - loss: 1.5163 - categorical_accuracy: 0.4042 - val_loss: 1.7032 - val_categorical_accuracy: 0.3981 - 524ms/epoch - 16ms/step\n",
      "Epoch 14/150\n",
      "32/32 - 1s - loss: 1.4641 - categorical_accuracy: 0.4628 - val_loss: 1.8582 - val_categorical_accuracy: 0.3148 - 573ms/epoch - 18ms/step\n",
      "Epoch 15/150\n",
      "32/32 - 1s - loss: 1.4213 - categorical_accuracy: 0.4320 - val_loss: 1.7994 - val_categorical_accuracy: 0.3380 - 524ms/epoch - 16ms/step\n",
      "Epoch 16/150\n",
      "32/32 - 1s - loss: 1.3946 - categorical_accuracy: 0.4538 - val_loss: 1.6697 - val_categorical_accuracy: 0.4236 - 518ms/epoch - 16ms/step\n",
      "Epoch 17/150\n",
      "32/32 - 1s - loss: 1.3682 - categorical_accuracy: 0.5015 - val_loss: 1.7698 - val_categorical_accuracy: 0.3542 - 525ms/epoch - 16ms/step\n",
      "Epoch 18/150\n",
      "32/32 - 1s - loss: 1.3400 - categorical_accuracy: 0.4707 - val_loss: 1.8357 - val_categorical_accuracy: 0.3426 - 525ms/epoch - 16ms/step\n",
      "Epoch 19/150\n",
      "32/32 - 1s - loss: 1.3040 - categorical_accuracy: 0.4926 - val_loss: 1.8743 - val_categorical_accuracy: 0.3681 - 551ms/epoch - 17ms/step\n",
      "Epoch 20/150\n",
      "32/32 - 1s - loss: 1.3149 - categorical_accuracy: 0.5084 - val_loss: 1.8322 - val_categorical_accuracy: 0.3218 - 530ms/epoch - 17ms/step\n",
      "Epoch 21/150\n",
      "32/32 - 1s - loss: 1.2855 - categorical_accuracy: 0.5134 - val_loss: 1.8476 - val_categorical_accuracy: 0.3588 - 518ms/epoch - 16ms/step\n",
      "Epoch 22/150\n",
      "32/32 - 1s - loss: 1.3017 - categorical_accuracy: 0.5104 - val_loss: 1.8639 - val_categorical_accuracy: 0.3681 - 524ms/epoch - 16ms/step\n",
      "Epoch 23/150\n",
      "32/32 - 1s - loss: 1.2290 - categorical_accuracy: 0.5005 - val_loss: 1.7583 - val_categorical_accuracy: 0.3866 - 531ms/epoch - 17ms/step\n",
      "Epoch 24/150\n",
      "32/32 - 1s - loss: 1.1860 - categorical_accuracy: 0.5432 - val_loss: 1.6788 - val_categorical_accuracy: 0.4861 - 550ms/epoch - 17ms/step\n",
      "Epoch 25/150\n",
      "32/32 - 1s - loss: 1.1868 - categorical_accuracy: 0.5591 - val_loss: 2.0256 - val_categorical_accuracy: 0.2940 - 550ms/epoch - 17ms/step\n",
      "Epoch 26/150\n",
      "32/32 - 1s - loss: 1.1969 - categorical_accuracy: 0.5452 - val_loss: 2.0358 - val_categorical_accuracy: 0.3681 - 526ms/epoch - 16ms/step\n",
      "Epoch 27/150\n",
      "32/32 - 1s - loss: 1.1744 - categorical_accuracy: 0.5412 - val_loss: 1.8784 - val_categorical_accuracy: 0.3866 - 526ms/epoch - 16ms/step\n",
      "Epoch 28/150\n",
      "32/32 - 1s - loss: 1.1559 - categorical_accuracy: 0.5521 - val_loss: 1.7614 - val_categorical_accuracy: 0.4167 - 532ms/epoch - 17ms/step\n",
      "Epoch 29/150\n",
      "32/32 - 1s - loss: 1.1090 - categorical_accuracy: 0.5680 - val_loss: 1.9476 - val_categorical_accuracy: 0.3634 - 529ms/epoch - 17ms/step\n",
      "Epoch 30/150\n",
      "32/32 - 1s - loss: 1.1149 - categorical_accuracy: 0.5730 - val_loss: 2.0916 - val_categorical_accuracy: 0.3333 - 528ms/epoch - 17ms/step\n",
      "Epoch 31/150\n",
      "32/32 - 1s - loss: 1.0841 - categorical_accuracy: 0.5621 - val_loss: 1.9835 - val_categorical_accuracy: 0.3750 - 540ms/epoch - 17ms/step\n",
      "Epoch 32/150\n",
      "32/32 - 1s - loss: 1.0596 - categorical_accuracy: 0.5889 - val_loss: 2.0554 - val_categorical_accuracy: 0.3796 - 550ms/epoch - 17ms/step\n",
      "Epoch 33/150\n",
      "32/32 - 1s - loss: 1.0808 - categorical_accuracy: 0.5829 - val_loss: 1.9815 - val_categorical_accuracy: 0.4005 - 536ms/epoch - 17ms/step\n",
      "Epoch 34/150\n",
      "32/32 - 1s - loss: 1.0266 - categorical_accuracy: 0.5799 - val_loss: 1.9982 - val_categorical_accuracy: 0.3981 - 553ms/epoch - 17ms/step\n",
      "Epoch 35/150\n",
      "32/32 - 1s - loss: 1.0257 - categorical_accuracy: 0.6107 - val_loss: 2.1028 - val_categorical_accuracy: 0.3542 - 528ms/epoch - 16ms/step\n",
      "Epoch 36/150\n",
      "32/32 - 1s - loss: 1.0093 - categorical_accuracy: 0.6127 - val_loss: 2.0409 - val_categorical_accuracy: 0.3796 - 531ms/epoch - 17ms/step\n",
      "Epoch 37/150\n",
      "32/32 - 1s - loss: 0.9589 - categorical_accuracy: 0.6147 - val_loss: 1.9536 - val_categorical_accuracy: 0.4120 - 530ms/epoch - 17ms/step\n",
      "Epoch 38/150\n",
      "32/32 - 1s - loss: 0.9712 - categorical_accuracy: 0.6296 - val_loss: 2.1267 - val_categorical_accuracy: 0.3634 - 528ms/epoch - 16ms/step\n",
      "Epoch 39/150\n",
      "32/32 - 1s - loss: 0.9922 - categorical_accuracy: 0.6266 - val_loss: 2.0870 - val_categorical_accuracy: 0.3611 - 528ms/epoch - 17ms/step\n",
      "Epoch 40/150\n",
      "32/32 - 1s - loss: 0.9959 - categorical_accuracy: 0.6177 - val_loss: 2.0877 - val_categorical_accuracy: 0.3819 - 546ms/epoch - 17ms/step\n",
      "Epoch 41/150\n",
      "32/32 - 1s - loss: 0.9424 - categorical_accuracy: 0.6425 - val_loss: 2.1907 - val_categorical_accuracy: 0.3611 - 522ms/epoch - 16ms/step\n",
      "Epoch 42/150\n",
      "32/32 - 0s - loss: 0.9131 - categorical_accuracy: 0.6326 - val_loss: 2.2200 - val_categorical_accuracy: 0.3912 - 446ms/epoch - 14ms/step\n",
      "Epoch 43/150\n",
      "32/32 - 0s - loss: 0.9458 - categorical_accuracy: 0.6197 - val_loss: 2.1007 - val_categorical_accuracy: 0.3657 - 452ms/epoch - 14ms/step\n",
      "Epoch 44/150\n",
      "32/32 - 0s - loss: 0.9006 - categorical_accuracy: 0.6564 - val_loss: 2.1769 - val_categorical_accuracy: 0.3866 - 449ms/epoch - 14ms/step\n",
      "Epoch 45/150\n",
      "32/32 - 0s - loss: 0.9002 - categorical_accuracy: 0.6961 - val_loss: 2.4249 - val_categorical_accuracy: 0.3194 - 451ms/epoch - 14ms/step\n",
      "Epoch 46/150\n",
      "32/32 - 0s - loss: 0.8811 - categorical_accuracy: 0.6475 - val_loss: 2.2444 - val_categorical_accuracy: 0.4282 - 459ms/epoch - 14ms/step\n",
      "Epoch 47/150\n",
      "32/32 - 0s - loss: 0.8847 - categorical_accuracy: 0.6375 - val_loss: 2.3061 - val_categorical_accuracy: 0.3519 - 457ms/epoch - 14ms/step\n",
      "Epoch 48/150\n",
      "32/32 - 0s - loss: 0.8436 - categorical_accuracy: 0.6524 - val_loss: 2.1938 - val_categorical_accuracy: 0.3981 - 452ms/epoch - 14ms/step\n",
      "Epoch 49/150\n",
      "32/32 - 0s - loss: 0.8226 - categorical_accuracy: 0.6822 - val_loss: 2.4005 - val_categorical_accuracy: 0.4051 - 448ms/epoch - 14ms/step\n",
      "Epoch 50/150\n",
      "32/32 - 0s - loss: 0.8821 - categorical_accuracy: 0.6455 - val_loss: 2.2225 - val_categorical_accuracy: 0.4074 - 448ms/epoch - 14ms/step\n",
      "Epoch 51/150\n",
      "32/32 - 0s - loss: 0.8481 - categorical_accuracy: 0.6763 - val_loss: 2.3353 - val_categorical_accuracy: 0.3819 - 448ms/epoch - 14ms/step\n",
      "Epoch 52/150\n",
      "32/32 - 0s - loss: 0.8112 - categorical_accuracy: 0.6783 - val_loss: 2.3773 - val_categorical_accuracy: 0.3935 - 452ms/epoch - 14ms/step\n",
      "Epoch 53/150\n",
      "32/32 - 0s - loss: 0.7925 - categorical_accuracy: 0.6862 - val_loss: 2.3434 - val_categorical_accuracy: 0.4421 - 447ms/epoch - 14ms/step\n",
      "Epoch 54/150\n",
      "32/32 - 0s - loss: 0.8182 - categorical_accuracy: 0.6862 - val_loss: 2.5325 - val_categorical_accuracy: 0.3750 - 451ms/epoch - 14ms/step\n",
      "Epoch 55/150\n",
      "32/32 - 0s - loss: 0.7905 - categorical_accuracy: 0.6912 - val_loss: 2.6420 - val_categorical_accuracy: 0.3843 - 451ms/epoch - 14ms/step\n",
      "Epoch 56/150\n",
      "32/32 - 0s - loss: 0.8050 - categorical_accuracy: 0.6802 - val_loss: 2.4919 - val_categorical_accuracy: 0.3750 - 446ms/epoch - 14ms/step\n",
      "Epoch 57/150\n",
      "32/32 - 0s - loss: 0.8177 - categorical_accuracy: 0.6713 - val_loss: 2.5094 - val_categorical_accuracy: 0.3727 - 452ms/epoch - 14ms/step\n",
      "Epoch 58/150\n",
      "32/32 - 0s - loss: 0.7658 - categorical_accuracy: 0.7021 - val_loss: 2.4789 - val_categorical_accuracy: 0.3819 - 459ms/epoch - 14ms/step\n",
      "Epoch 59/150\n",
      "32/32 - 0s - loss: 0.7924 - categorical_accuracy: 0.6912 - val_loss: 2.4795 - val_categorical_accuracy: 0.3981 - 447ms/epoch - 14ms/step\n",
      "Epoch 60/150\n",
      "32/32 - 0s - loss: 0.7602 - categorical_accuracy: 0.7001 - val_loss: 2.5165 - val_categorical_accuracy: 0.3843 - 449ms/epoch - 14ms/step\n",
      "Epoch 61/150\n",
      "32/32 - 0s - loss: 0.7424 - categorical_accuracy: 0.7011 - val_loss: 2.5323 - val_categorical_accuracy: 0.3912 - 458ms/epoch - 14ms/step\n",
      "Epoch 62/150\n",
      "32/32 - 0s - loss: 0.8141 - categorical_accuracy: 0.6902 - val_loss: 2.5911 - val_categorical_accuracy: 0.3981 - 459ms/epoch - 14ms/step\n",
      "Epoch 63/150\n",
      "32/32 - 0s - loss: 0.7650 - categorical_accuracy: 0.7041 - val_loss: 2.5453 - val_categorical_accuracy: 0.3681 - 454ms/epoch - 14ms/step\n",
      "Epoch 64/150\n",
      "32/32 - 0s - loss: 0.7034 - categorical_accuracy: 0.7319 - val_loss: 2.6064 - val_categorical_accuracy: 0.4005 - 456ms/epoch - 14ms/step\n",
      "Epoch 65/150\n",
      "32/32 - 0s - loss: 0.7567 - categorical_accuracy: 0.7071 - val_loss: 2.5859 - val_categorical_accuracy: 0.3819 - 460ms/epoch - 14ms/step\n",
      "Epoch 66/150\n",
      "32/32 - 0s - loss: 0.7461 - categorical_accuracy: 0.7110 - val_loss: 2.7641 - val_categorical_accuracy: 0.3958 - 462ms/epoch - 14ms/step\n",
      "Epoch 67/150\n",
      "32/32 - 0s - loss: 0.6904 - categorical_accuracy: 0.7319 - val_loss: 2.7877 - val_categorical_accuracy: 0.3634 - 453ms/epoch - 14ms/step\n",
      "Epoch 68/150\n",
      "32/32 - 0s - loss: 0.7251 - categorical_accuracy: 0.7210 - val_loss: 2.7667 - val_categorical_accuracy: 0.3704 - 460ms/epoch - 14ms/step\n",
      "Epoch 69/150\n",
      "32/32 - 0s - loss: 0.7108 - categorical_accuracy: 0.7349 - val_loss: 2.7199 - val_categorical_accuracy: 0.3981 - 471ms/epoch - 15ms/step\n",
      "Epoch 70/150\n",
      "32/32 - 0s - loss: 0.6923 - categorical_accuracy: 0.7180 - val_loss: 2.9427 - val_categorical_accuracy: 0.3565 - 456ms/epoch - 14ms/step\n",
      "Epoch 71/150\n",
      "32/32 - 0s - loss: 0.6964 - categorical_accuracy: 0.7210 - val_loss: 3.0300 - val_categorical_accuracy: 0.3843 - 454ms/epoch - 14ms/step\n",
      "Epoch 72/150\n",
      "32/32 - 0s - loss: 0.6790 - categorical_accuracy: 0.7378 - val_loss: 2.9068 - val_categorical_accuracy: 0.3588 - 458ms/epoch - 14ms/step\n",
      "Epoch 73/150\n",
      "32/32 - 0s - loss: 0.7065 - categorical_accuracy: 0.7041 - val_loss: 3.0146 - val_categorical_accuracy: 0.3750 - 456ms/epoch - 14ms/step\n",
      "Epoch 74/150\n",
      "32/32 - 0s - loss: 0.6988 - categorical_accuracy: 0.7219 - val_loss: 2.9709 - val_categorical_accuracy: 0.3773 - 458ms/epoch - 14ms/step\n",
      "Epoch 75/150\n",
      "32/32 - 0s - loss: 0.7019 - categorical_accuracy: 0.7229 - val_loss: 2.7907 - val_categorical_accuracy: 0.3935 - 454ms/epoch - 14ms/step\n",
      "Epoch 76/150\n",
      "32/32 - 0s - loss: 0.6630 - categorical_accuracy: 0.7329 - val_loss: 3.0625 - val_categorical_accuracy: 0.3750 - 451ms/epoch - 14ms/step\n",
      "Epoch 77/150\n",
      "32/32 - 0s - loss: 0.6965 - categorical_accuracy: 0.7150 - val_loss: 2.9846 - val_categorical_accuracy: 0.3542 - 457ms/epoch - 14ms/step\n",
      "Epoch 78/150\n",
      "32/32 - 0s - loss: 0.6942 - categorical_accuracy: 0.7100 - val_loss: 2.9883 - val_categorical_accuracy: 0.3588 - 453ms/epoch - 14ms/step\n",
      "Epoch 79/150\n",
      "32/32 - 0s - loss: 0.6507 - categorical_accuracy: 0.7349 - val_loss: 2.9655 - val_categorical_accuracy: 0.3611 - 458ms/epoch - 14ms/step\n",
      "Epoch 80/150\n",
      "32/32 - 0s - loss: 0.6408 - categorical_accuracy: 0.7289 - val_loss: 2.9556 - val_categorical_accuracy: 0.3519 - 447ms/epoch - 14ms/step\n",
      "Epoch 81/150\n",
      "32/32 - 0s - loss: 0.6498 - categorical_accuracy: 0.7428 - val_loss: 2.8698 - val_categorical_accuracy: 0.3773 - 455ms/epoch - 14ms/step\n",
      "Epoch 82/150\n",
      "32/32 - 0s - loss: 0.6063 - categorical_accuracy: 0.7607 - val_loss: 3.0911 - val_categorical_accuracy: 0.3657 - 458ms/epoch - 14ms/step\n",
      "Epoch 83/150\n",
      "32/32 - 0s - loss: 0.6038 - categorical_accuracy: 0.7478 - val_loss: 3.1183 - val_categorical_accuracy: 0.3819 - 457ms/epoch - 14ms/step\n",
      "Epoch 84/150\n",
      "32/32 - 0s - loss: 0.6067 - categorical_accuracy: 0.7527 - val_loss: 3.1334 - val_categorical_accuracy: 0.3634 - 455ms/epoch - 14ms/step\n",
      "Epoch 85/150\n",
      "32/32 - 0s - loss: 0.5993 - categorical_accuracy: 0.7517 - val_loss: 3.1398 - val_categorical_accuracy: 0.3727 - 461ms/epoch - 14ms/step\n",
      "Epoch 86/150\n",
      "32/32 - 0s - loss: 0.5965 - categorical_accuracy: 0.7438 - val_loss: 3.3088 - val_categorical_accuracy: 0.3727 - 454ms/epoch - 14ms/step\n",
      "Epoch 87/150\n",
      "32/32 - 0s - loss: 0.5809 - categorical_accuracy: 0.7557 - val_loss: 3.1520 - val_categorical_accuracy: 0.3866 - 451ms/epoch - 14ms/step\n",
      "Epoch 88/150\n",
      "32/32 - 0s - loss: 0.5961 - categorical_accuracy: 0.7557 - val_loss: 3.4139 - val_categorical_accuracy: 0.3681 - 458ms/epoch - 14ms/step\n",
      "Epoch 89/150\n",
      "32/32 - 0s - loss: 0.6029 - categorical_accuracy: 0.7458 - val_loss: 3.3813 - val_categorical_accuracy: 0.3565 - 455ms/epoch - 14ms/step\n",
      "Epoch 90/150\n",
      "32/32 - 0s - loss: 0.6265 - categorical_accuracy: 0.7368 - val_loss: 3.0941 - val_categorical_accuracy: 0.4028 - 463ms/epoch - 14ms/step\n",
      "Epoch 91/150\n",
      "32/32 - 0s - loss: 0.6902 - categorical_accuracy: 0.7279 - val_loss: 3.2487 - val_categorical_accuracy: 0.3519 - 460ms/epoch - 14ms/step\n",
      "Epoch 92/150\n",
      "32/32 - 0s - loss: 0.6803 - categorical_accuracy: 0.7329 - val_loss: 3.0071 - val_categorical_accuracy: 0.3935 - 469ms/epoch - 15ms/step\n",
      "Epoch 93/150\n",
      "32/32 - 0s - loss: 0.6084 - categorical_accuracy: 0.7358 - val_loss: 3.1652 - val_categorical_accuracy: 0.3449 - 461ms/epoch - 14ms/step\n",
      "Epoch 94/150\n",
      "32/32 - 0s - loss: 0.5907 - categorical_accuracy: 0.7627 - val_loss: 3.1927 - val_categorical_accuracy: 0.3750 - 462ms/epoch - 14ms/step\n",
      "Epoch 95/150\n",
      "32/32 - 0s - loss: 0.5803 - categorical_accuracy: 0.7488 - val_loss: 3.3221 - val_categorical_accuracy: 0.3634 - 458ms/epoch - 14ms/step\n",
      "Epoch 96/150\n",
      "32/32 - 0s - loss: 0.6079 - categorical_accuracy: 0.7498 - val_loss: 3.2442 - val_categorical_accuracy: 0.3611 - 467ms/epoch - 15ms/step\n",
      "Epoch 97/150\n",
      "32/32 - 0s - loss: 0.5865 - categorical_accuracy: 0.7378 - val_loss: 3.3084 - val_categorical_accuracy: 0.3588 - 462ms/epoch - 14ms/step\n",
      "Epoch 98/150\n",
      "32/32 - 0s - loss: 0.5401 - categorical_accuracy: 0.7686 - val_loss: 3.5319 - val_categorical_accuracy: 0.3495 - 465ms/epoch - 15ms/step\n",
      "Epoch 99/150\n",
      "32/32 - 0s - loss: 0.5504 - categorical_accuracy: 0.7646 - val_loss: 3.4087 - val_categorical_accuracy: 0.3727 - 467ms/epoch - 15ms/step\n",
      "Epoch 100/150\n",
      "32/32 - 0s - loss: 0.5609 - categorical_accuracy: 0.7607 - val_loss: 3.4478 - val_categorical_accuracy: 0.3657 - 456ms/epoch - 14ms/step\n",
      "Epoch 101/150\n",
      "32/32 - 0s - loss: 0.5501 - categorical_accuracy: 0.7716 - val_loss: 3.6039 - val_categorical_accuracy: 0.3565 - 466ms/epoch - 15ms/step\n",
      "Epoch 102/150\n",
      "32/32 - 0s - loss: 0.5749 - categorical_accuracy: 0.7597 - val_loss: 3.4409 - val_categorical_accuracy: 0.3704 - 460ms/epoch - 14ms/step\n",
      "Epoch 103/150\n",
      "32/32 - 0s - loss: 0.5448 - categorical_accuracy: 0.7726 - val_loss: 3.5732 - val_categorical_accuracy: 0.3704 - 459ms/epoch - 14ms/step\n",
      "Epoch 104/150\n",
      "32/32 - 0s - loss: 0.5325 - categorical_accuracy: 0.7637 - val_loss: 3.6099 - val_categorical_accuracy: 0.3704 - 452ms/epoch - 14ms/step\n",
      "Epoch 105/150\n",
      "32/32 - 0s - loss: 0.5371 - categorical_accuracy: 0.7567 - val_loss: 3.6246 - val_categorical_accuracy: 0.3912 - 453ms/epoch - 14ms/step\n",
      "Epoch 106/150\n",
      "32/32 - 0s - loss: 0.5358 - categorical_accuracy: 0.7706 - val_loss: 3.5049 - val_categorical_accuracy: 0.3889 - 454ms/epoch - 14ms/step\n",
      "Epoch 107/150\n",
      "32/32 - 0s - loss: 0.5318 - categorical_accuracy: 0.7686 - val_loss: 3.6233 - val_categorical_accuracy: 0.3704 - 455ms/epoch - 14ms/step\n",
      "Epoch 108/150\n",
      "32/32 - 0s - loss: 0.5099 - categorical_accuracy: 0.7746 - val_loss: 3.6550 - val_categorical_accuracy: 0.3634 - 454ms/epoch - 14ms/step\n",
      "Epoch 109/150\n",
      "32/32 - 0s - loss: 0.5539 - categorical_accuracy: 0.7746 - val_loss: 3.6331 - val_categorical_accuracy: 0.3889 - 452ms/epoch - 14ms/step\n",
      "Epoch 110/150\n",
      "32/32 - 0s - loss: 0.5112 - categorical_accuracy: 0.7865 - val_loss: 3.7333 - val_categorical_accuracy: 0.3681 - 458ms/epoch - 14ms/step\n",
      "Epoch 111/150\n",
      "32/32 - 0s - loss: 0.5229 - categorical_accuracy: 0.7646 - val_loss: 3.7468 - val_categorical_accuracy: 0.3634 - 460ms/epoch - 14ms/step\n",
      "Epoch 112/150\n",
      "32/32 - 0s - loss: 0.5431 - categorical_accuracy: 0.7746 - val_loss: 3.7382 - val_categorical_accuracy: 0.3796 - 491ms/epoch - 15ms/step\n",
      "Epoch 113/150\n",
      "32/32 - 0s - loss: 0.5164 - categorical_accuracy: 0.7646 - val_loss: 3.7743 - val_categorical_accuracy: 0.3657 - 458ms/epoch - 14ms/step\n",
      "Epoch 114/150\n",
      "32/32 - 1s - loss: 0.5226 - categorical_accuracy: 0.7835 - val_loss: 3.7237 - val_categorical_accuracy: 0.3565 - 513ms/epoch - 16ms/step\n",
      "Epoch 115/150\n",
      "32/32 - 0s - loss: 0.5192 - categorical_accuracy: 0.7885 - val_loss: 3.9473 - val_categorical_accuracy: 0.3495 - 483ms/epoch - 15ms/step\n",
      "Epoch 116/150\n",
      "32/32 - 0s - loss: 0.5271 - categorical_accuracy: 0.7577 - val_loss: 3.8334 - val_categorical_accuracy: 0.3681 - 456ms/epoch - 14ms/step\n",
      "Epoch 117/150\n",
      "32/32 - 0s - loss: 0.5364 - categorical_accuracy: 0.7676 - val_loss: 3.6285 - val_categorical_accuracy: 0.3750 - 455ms/epoch - 14ms/step\n",
      "Epoch 118/150\n",
      "32/32 - 0s - loss: 0.4852 - categorical_accuracy: 0.7954 - val_loss: 3.9167 - val_categorical_accuracy: 0.3634 - 451ms/epoch - 14ms/step\n",
      "Epoch 119/150\n",
      "32/32 - 0s - loss: 0.4798 - categorical_accuracy: 0.7885 - val_loss: 3.7865 - val_categorical_accuracy: 0.3819 - 450ms/epoch - 14ms/step\n",
      "Epoch 120/150\n",
      "32/32 - 0s - loss: 0.4975 - categorical_accuracy: 0.7805 - val_loss: 3.9770 - val_categorical_accuracy: 0.3449 - 456ms/epoch - 14ms/step\n",
      "Epoch 121/150\n",
      "32/32 - 0s - loss: 0.4519 - categorical_accuracy: 0.7865 - val_loss: 4.0398 - val_categorical_accuracy: 0.3588 - 453ms/epoch - 14ms/step\n",
      "Epoch 122/150\n",
      "32/32 - 0s - loss: 0.5226 - categorical_accuracy: 0.7746 - val_loss: 4.1482 - val_categorical_accuracy: 0.3889 - 455ms/epoch - 14ms/step\n",
      "Epoch 123/150\n",
      "32/32 - 0s - loss: 0.4616 - categorical_accuracy: 0.7815 - val_loss: 3.8568 - val_categorical_accuracy: 0.3681 - 451ms/epoch - 14ms/step\n",
      "Epoch 124/150\n",
      "32/32 - 0s - loss: 0.4603 - categorical_accuracy: 0.7925 - val_loss: 4.1441 - val_categorical_accuracy: 0.3889 - 452ms/epoch - 14ms/step\n",
      "Epoch 125/150\n",
      "32/32 - 0s - loss: 0.4678 - categorical_accuracy: 0.7825 - val_loss: 3.8643 - val_categorical_accuracy: 0.3843 - 451ms/epoch - 14ms/step\n",
      "Epoch 126/150\n",
      "32/32 - 0s - loss: 0.4873 - categorical_accuracy: 0.7865 - val_loss: 4.0982 - val_categorical_accuracy: 0.3449 - 461ms/epoch - 14ms/step\n",
      "Epoch 127/150\n",
      "32/32 - 0s - loss: 0.4612 - categorical_accuracy: 0.7855 - val_loss: 4.0004 - val_categorical_accuracy: 0.3588 - 466ms/epoch - 15ms/step\n",
      "Epoch 128/150\n",
      "32/32 - 0s - loss: 0.4411 - categorical_accuracy: 0.7934 - val_loss: 4.0923 - val_categorical_accuracy: 0.3819 - 455ms/epoch - 14ms/step\n",
      "Epoch 129/150\n",
      "32/32 - 0s - loss: 0.5243 - categorical_accuracy: 0.7805 - val_loss: 4.0687 - val_categorical_accuracy: 0.3843 - 463ms/epoch - 14ms/step\n",
      "Epoch 130/150\n",
      "32/32 - 0s - loss: 0.5350 - categorical_accuracy: 0.7746 - val_loss: 4.2245 - val_categorical_accuracy: 0.3750 - 449ms/epoch - 14ms/step\n",
      "Epoch 131/150\n",
      "32/32 - 0s - loss: 0.5088 - categorical_accuracy: 0.7746 - val_loss: 4.0475 - val_categorical_accuracy: 0.3819 - 455ms/epoch - 14ms/step\n",
      "Epoch 132/150\n",
      "32/32 - 0s - loss: 0.5044 - categorical_accuracy: 0.7686 - val_loss: 4.2132 - val_categorical_accuracy: 0.3843 - 460ms/epoch - 14ms/step\n",
      "Epoch 133/150\n",
      "32/32 - 0s - loss: 0.4709 - categorical_accuracy: 0.7805 - val_loss: 3.9713 - val_categorical_accuracy: 0.4028 - 453ms/epoch - 14ms/step\n",
      "Epoch 134/150\n",
      "32/32 - 0s - loss: 0.4618 - categorical_accuracy: 0.7805 - val_loss: 4.0436 - val_categorical_accuracy: 0.3727 - 456ms/epoch - 14ms/step\n",
      "Epoch 135/150\n",
      "32/32 - 0s - loss: 0.4398 - categorical_accuracy: 0.7964 - val_loss: 4.1115 - val_categorical_accuracy: 0.3981 - 465ms/epoch - 15ms/step\n",
      "Epoch 136/150\n",
      "32/32 - 0s - loss: 0.4573 - categorical_accuracy: 0.7964 - val_loss: 4.3530 - val_categorical_accuracy: 0.3634 - 458ms/epoch - 14ms/step\n",
      "Epoch 137/150\n",
      "32/32 - 0s - loss: 0.4509 - categorical_accuracy: 0.7934 - val_loss: 4.1496 - val_categorical_accuracy: 0.3935 - 462ms/epoch - 14ms/step\n",
      "Epoch 138/150\n",
      "32/32 - 0s - loss: 0.4150 - categorical_accuracy: 0.8093 - val_loss: 4.2501 - val_categorical_accuracy: 0.3588 - 461ms/epoch - 14ms/step\n",
      "Epoch 139/150\n",
      "32/32 - 0s - loss: 0.4071 - categorical_accuracy: 0.8034 - val_loss: 4.2461 - val_categorical_accuracy: 0.3843 - 448ms/epoch - 14ms/step\n",
      "Epoch 140/150\n",
      "32/32 - 0s - loss: 0.4243 - categorical_accuracy: 0.8034 - val_loss: 4.2501 - val_categorical_accuracy: 0.3843 - 459ms/epoch - 14ms/step\n",
      "Epoch 141/150\n",
      "32/32 - 0s - loss: 0.4372 - categorical_accuracy: 0.7934 - val_loss: 4.2077 - val_categorical_accuracy: 0.3889 - 461ms/epoch - 14ms/step\n",
      "Epoch 142/150\n",
      "32/32 - 0s - loss: 0.4179 - categorical_accuracy: 0.8044 - val_loss: 4.5154 - val_categorical_accuracy: 0.3958 - 458ms/epoch - 14ms/step\n",
      "Epoch 143/150\n",
      "32/32 - 0s - loss: 0.4277 - categorical_accuracy: 0.7974 - val_loss: 4.3309 - val_categorical_accuracy: 0.3681 - 453ms/epoch - 14ms/step\n",
      "Epoch 144/150\n",
      "32/32 - 0s - loss: 0.4591 - categorical_accuracy: 0.7895 - val_loss: 4.0170 - val_categorical_accuracy: 0.3866 - 456ms/epoch - 14ms/step\n",
      "Epoch 145/150\n",
      "32/32 - 0s - loss: 0.4864 - categorical_accuracy: 0.7686 - val_loss: 4.3077 - val_categorical_accuracy: 0.3866 - 458ms/epoch - 14ms/step\n",
      "Epoch 146/150\n",
      "32/32 - 0s - loss: 0.4414 - categorical_accuracy: 0.8044 - val_loss: 4.2692 - val_categorical_accuracy: 0.3843 - 458ms/epoch - 14ms/step\n",
      "Epoch 147/150\n",
      "32/32 - 0s - loss: 0.4251 - categorical_accuracy: 0.8014 - val_loss: 4.1535 - val_categorical_accuracy: 0.4097 - 463ms/epoch - 14ms/step\n",
      "Epoch 148/150\n",
      "32/32 - 0s - loss: 0.4261 - categorical_accuracy: 0.8034 - val_loss: 4.2861 - val_categorical_accuracy: 0.3912 - 460ms/epoch - 14ms/step\n",
      "Epoch 149/150\n",
      "32/32 - 0s - loss: 0.4221 - categorical_accuracy: 0.8024 - val_loss: 4.5850 - val_categorical_accuracy: 0.3866 - 458ms/epoch - 14ms/step\n",
      "Epoch 150/150\n",
      "32/32 - 0s - loss: 0.4255 - categorical_accuracy: 0.8153 - val_loss: 4.2539 - val_categorical_accuracy: 0.3866 - 455ms/epoch - 14ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   2   1   2   0   5   0   1   2]\n",
      " [  6 102   6  12   6  33   7   4  13]\n",
      " [  0   6  10   8   1   1   7   2   0]\n",
      " [  3   8   9  13   2   0   9   3   5]\n",
      " [  0   1   0   0   4   0   4   2   4]\n",
      " [  2   4   1   0   0   2   1   2   2]\n",
      " [  2   4   2   7   2   1  13   7   5]\n",
      " [  0   1   1   5   1   0  11  11   6]\n",
      " [  1   3   2   4   2   1   7   3  11]]\n",
      ">#1: 38.657\n",
      "Epoch 1/150\n",
      "32/32 - 1s - loss: 2.1353 - categorical_accuracy: 0.1708 - val_loss: 1.9219 - val_categorical_accuracy: 0.3634 - 674ms/epoch - 21ms/step\n",
      "Epoch 2/150\n",
      "32/32 - 0s - loss: 2.0327 - categorical_accuracy: 0.2026 - val_loss: 1.9221 - val_categorical_accuracy: 0.1968 - 445ms/epoch - 14ms/step\n",
      "Epoch 3/150\n",
      "32/32 - 0s - loss: 1.9077 - categorical_accuracy: 0.1768 - val_loss: 1.7783 - val_categorical_accuracy: 0.3241 - 442ms/epoch - 14ms/step\n",
      "Epoch 4/150\n",
      "32/32 - 0s - loss: 1.8511 - categorical_accuracy: 0.2562 - val_loss: 1.7969 - val_categorical_accuracy: 0.2870 - 445ms/epoch - 14ms/step\n",
      "Epoch 5/150\n",
      "32/32 - 0s - loss: 1.7796 - categorical_accuracy: 0.3059 - val_loss: 1.6829 - val_categorical_accuracy: 0.3588 - 445ms/epoch - 14ms/step\n",
      "Epoch 6/150\n",
      "32/32 - 0s - loss: 1.7516 - categorical_accuracy: 0.3049 - val_loss: 1.8252 - val_categorical_accuracy: 0.2847 - 441ms/epoch - 14ms/step\n",
      "Epoch 7/150\n",
      "32/32 - 0s - loss: 1.6993 - categorical_accuracy: 0.3297 - val_loss: 1.8230 - val_categorical_accuracy: 0.2500 - 489ms/epoch - 15ms/step\n",
      "Epoch 8/150\n",
      "32/32 - 0s - loss: 1.6428 - categorical_accuracy: 0.3714 - val_loss: 1.8500 - val_categorical_accuracy: 0.2546 - 464ms/epoch - 15ms/step\n",
      "Epoch 9/150\n",
      "32/32 - 0s - loss: 1.5674 - categorical_accuracy: 0.3992 - val_loss: 1.7119 - val_categorical_accuracy: 0.3819 - 445ms/epoch - 14ms/step\n",
      "Epoch 10/150\n",
      "32/32 - 0s - loss: 1.5459 - categorical_accuracy: 0.4091 - val_loss: 1.7703 - val_categorical_accuracy: 0.3079 - 444ms/epoch - 14ms/step\n",
      "Epoch 11/150\n",
      "32/32 - 0s - loss: 1.5213 - categorical_accuracy: 0.4111 - val_loss: 1.7793 - val_categorical_accuracy: 0.2685 - 450ms/epoch - 14ms/step\n",
      "Epoch 12/150\n",
      "32/32 - 0s - loss: 1.4790 - categorical_accuracy: 0.4479 - val_loss: 1.9552 - val_categorical_accuracy: 0.2523 - 453ms/epoch - 14ms/step\n",
      "Epoch 13/150\n",
      "32/32 - 0s - loss: 1.4647 - categorical_accuracy: 0.4499 - val_loss: 1.8173 - val_categorical_accuracy: 0.3287 - 449ms/epoch - 14ms/step\n",
      "Epoch 14/150\n",
      "32/32 - 0s - loss: 1.4361 - categorical_accuracy: 0.4578 - val_loss: 1.8245 - val_categorical_accuracy: 0.3449 - 462ms/epoch - 14ms/step\n",
      "Epoch 15/150\n",
      "32/32 - 0s - loss: 1.3878 - categorical_accuracy: 0.5223 - val_loss: 1.8911 - val_categorical_accuracy: 0.3079 - 447ms/epoch - 14ms/step\n",
      "Epoch 16/150\n",
      "32/32 - 0s - loss: 1.3828 - categorical_accuracy: 0.4628 - val_loss: 1.9375 - val_categorical_accuracy: 0.2639 - 455ms/epoch - 14ms/step\n",
      "Epoch 17/150\n",
      "32/32 - 0s - loss: 1.3461 - categorical_accuracy: 0.4906 - val_loss: 1.7563 - val_categorical_accuracy: 0.3750 - 453ms/epoch - 14ms/step\n",
      "Epoch 18/150\n",
      "32/32 - 0s - loss: 1.2927 - categorical_accuracy: 0.5204 - val_loss: 1.7734 - val_categorical_accuracy: 0.3958 - 467ms/epoch - 15ms/step\n",
      "Epoch 19/150\n",
      "32/32 - 0s - loss: 1.2750 - categorical_accuracy: 0.5025 - val_loss: 1.7704 - val_categorical_accuracy: 0.3935 - 464ms/epoch - 15ms/step\n",
      "Epoch 20/150\n",
      "32/32 - 0s - loss: 1.2950 - categorical_accuracy: 0.5025 - val_loss: 1.9211 - val_categorical_accuracy: 0.3403 - 465ms/epoch - 15ms/step\n",
      "Epoch 21/150\n",
      "32/32 - 0s - loss: 1.2516 - categorical_accuracy: 0.5323 - val_loss: 1.8492 - val_categorical_accuracy: 0.3264 - 470ms/epoch - 15ms/step\n",
      "Epoch 22/150\n",
      "32/32 - 0s - loss: 1.1861 - categorical_accuracy: 0.5541 - val_loss: 1.8970 - val_categorical_accuracy: 0.3426 - 478ms/epoch - 15ms/step\n",
      "Epoch 23/150\n",
      "32/32 - 0s - loss: 1.1901 - categorical_accuracy: 0.5521 - val_loss: 1.9227 - val_categorical_accuracy: 0.3472 - 470ms/epoch - 15ms/step\n",
      "Epoch 24/150\n",
      "32/32 - 0s - loss: 1.1585 - categorical_accuracy: 0.5541 - val_loss: 1.9616 - val_categorical_accuracy: 0.3472 - 476ms/epoch - 15ms/step\n",
      "Epoch 25/150\n",
      "32/32 - 1s - loss: 1.1566 - categorical_accuracy: 0.5412 - val_loss: 1.8073 - val_categorical_accuracy: 0.4190 - 504ms/epoch - 16ms/step\n",
      "Epoch 26/150\n",
      "32/32 - 0s - loss: 1.1150 - categorical_accuracy: 0.5611 - val_loss: 2.0941 - val_categorical_accuracy: 0.3356 - 466ms/epoch - 15ms/step\n",
      "Epoch 27/150\n",
      "32/32 - 0s - loss: 1.1329 - categorical_accuracy: 0.5641 - val_loss: 1.9816 - val_categorical_accuracy: 0.3727 - 464ms/epoch - 14ms/step\n",
      "Epoch 28/150\n",
      "32/32 - 0s - loss: 1.1127 - categorical_accuracy: 0.5770 - val_loss: 2.0577 - val_categorical_accuracy: 0.3727 - 464ms/epoch - 15ms/step\n",
      "Epoch 29/150\n",
      "32/32 - 0s - loss: 1.0655 - categorical_accuracy: 0.5968 - val_loss: 1.9657 - val_categorical_accuracy: 0.4028 - 472ms/epoch - 15ms/step\n",
      "Epoch 30/150\n",
      "32/32 - 0s - loss: 1.0436 - categorical_accuracy: 0.6167 - val_loss: 2.2103 - val_categorical_accuracy: 0.2894 - 464ms/epoch - 15ms/step\n",
      "Epoch 31/150\n",
      "32/32 - 0s - loss: 1.0643 - categorical_accuracy: 0.5660 - val_loss: 2.1986 - val_categorical_accuracy: 0.3218 - 452ms/epoch - 14ms/step\n",
      "Epoch 32/150\n",
      "32/32 - 0s - loss: 1.0386 - categorical_accuracy: 0.6058 - val_loss: 2.0948 - val_categorical_accuracy: 0.3611 - 450ms/epoch - 14ms/step\n",
      "Epoch 33/150\n",
      "32/32 - 0s - loss: 1.0339 - categorical_accuracy: 0.5978 - val_loss: 2.1393 - val_categorical_accuracy: 0.3634 - 448ms/epoch - 14ms/step\n",
      "Epoch 34/150\n",
      "32/32 - 0s - loss: 1.0173 - categorical_accuracy: 0.6127 - val_loss: 2.0479 - val_categorical_accuracy: 0.3750 - 457ms/epoch - 14ms/step\n",
      "Epoch 35/150\n",
      "32/32 - 0s - loss: 0.9446 - categorical_accuracy: 0.6415 - val_loss: 2.2468 - val_categorical_accuracy: 0.3704 - 454ms/epoch - 14ms/step\n",
      "Epoch 36/150\n",
      "32/32 - 0s - loss: 0.9667 - categorical_accuracy: 0.6256 - val_loss: 2.1834 - val_categorical_accuracy: 0.3796 - 453ms/epoch - 14ms/step\n",
      "Epoch 37/150\n",
      "32/32 - 0s - loss: 0.9540 - categorical_accuracy: 0.6395 - val_loss: 2.3083 - val_categorical_accuracy: 0.3542 - 457ms/epoch - 14ms/step\n",
      "Epoch 38/150\n",
      "32/32 - 0s - loss: 0.9635 - categorical_accuracy: 0.6415 - val_loss: 2.5844 - val_categorical_accuracy: 0.3056 - 458ms/epoch - 14ms/step\n",
      "Epoch 39/150\n",
      "32/32 - 0s - loss: 0.9406 - categorical_accuracy: 0.6226 - val_loss: 2.1206 - val_categorical_accuracy: 0.3750 - 453ms/epoch - 14ms/step\n",
      "Epoch 40/150\n",
      "32/32 - 0s - loss: 0.8794 - categorical_accuracy: 0.6475 - val_loss: 2.2152 - val_categorical_accuracy: 0.3750 - 458ms/epoch - 14ms/step\n",
      "Epoch 41/150\n",
      "32/32 - 0s - loss: 0.8421 - categorical_accuracy: 0.6673 - val_loss: 2.4621 - val_categorical_accuracy: 0.4097 - 451ms/epoch - 14ms/step\n",
      "Epoch 42/150\n",
      "32/32 - 0s - loss: 0.8906 - categorical_accuracy: 0.6534 - val_loss: 2.2913 - val_categorical_accuracy: 0.3380 - 449ms/epoch - 14ms/step\n",
      "Epoch 43/150\n",
      "32/32 - 0s - loss: 0.8718 - categorical_accuracy: 0.6624 - val_loss: 2.2898 - val_categorical_accuracy: 0.3704 - 456ms/epoch - 14ms/step\n",
      "Epoch 44/150\n",
      "32/32 - 0s - loss: 0.8767 - categorical_accuracy: 0.6425 - val_loss: 2.5293 - val_categorical_accuracy: 0.4005 - 455ms/epoch - 14ms/step\n",
      "Epoch 45/150\n",
      "32/32 - 0s - loss: 0.8833 - categorical_accuracy: 0.6693 - val_loss: 2.4718 - val_categorical_accuracy: 0.3542 - 456ms/epoch - 14ms/step\n",
      "Epoch 46/150\n",
      "32/32 - 0s - loss: 0.8074 - categorical_accuracy: 0.6743 - val_loss: 2.4037 - val_categorical_accuracy: 0.3565 - 453ms/epoch - 14ms/step\n",
      "Epoch 47/150\n",
      "32/32 - 0s - loss: 0.8231 - categorical_accuracy: 0.6723 - val_loss: 2.6055 - val_categorical_accuracy: 0.3634 - 447ms/epoch - 14ms/step\n",
      "Epoch 48/150\n",
      "32/32 - 0s - loss: 0.8572 - categorical_accuracy: 0.6604 - val_loss: 2.5567 - val_categorical_accuracy: 0.3565 - 455ms/epoch - 14ms/step\n",
      "Epoch 49/150\n",
      "32/32 - 0s - loss: 0.8235 - categorical_accuracy: 0.6822 - val_loss: 2.5970 - val_categorical_accuracy: 0.3380 - 451ms/epoch - 14ms/step\n",
      "Epoch 50/150\n",
      "32/32 - 0s - loss: 0.8043 - categorical_accuracy: 0.6862 - val_loss: 2.5544 - val_categorical_accuracy: 0.4074 - 468ms/epoch - 15ms/step\n",
      "Epoch 51/150\n",
      "32/32 - 0s - loss: 0.8028 - categorical_accuracy: 0.6882 - val_loss: 2.5531 - val_categorical_accuracy: 0.3819 - 456ms/epoch - 14ms/step\n",
      "Epoch 52/150\n",
      "32/32 - 0s - loss: 0.8083 - categorical_accuracy: 0.6703 - val_loss: 2.5630 - val_categorical_accuracy: 0.3750 - 445ms/epoch - 14ms/step\n",
      "Epoch 53/150\n",
      "32/32 - 0s - loss: 0.7565 - categorical_accuracy: 0.7021 - val_loss: 2.5048 - val_categorical_accuracy: 0.3773 - 445ms/epoch - 14ms/step\n",
      "Epoch 54/150\n",
      "32/32 - 0s - loss: 0.7638 - categorical_accuracy: 0.6922 - val_loss: 2.5000 - val_categorical_accuracy: 0.3773 - 451ms/epoch - 14ms/step\n",
      "Epoch 55/150\n",
      "32/32 - 0s - loss: 0.7371 - categorical_accuracy: 0.6922 - val_loss: 2.7216 - val_categorical_accuracy: 0.3750 - 449ms/epoch - 14ms/step\n",
      "Epoch 56/150\n",
      "32/32 - 0s - loss: 0.8124 - categorical_accuracy: 0.6812 - val_loss: 2.6585 - val_categorical_accuracy: 0.3611 - 459ms/epoch - 14ms/step\n",
      "Epoch 57/150\n",
      "32/32 - 0s - loss: 0.7320 - categorical_accuracy: 0.7130 - val_loss: 2.6377 - val_categorical_accuracy: 0.3796 - 448ms/epoch - 14ms/step\n",
      "Epoch 58/150\n",
      "32/32 - 0s - loss: 0.7271 - categorical_accuracy: 0.6971 - val_loss: 2.7783 - val_categorical_accuracy: 0.3449 - 451ms/epoch - 14ms/step\n",
      "Epoch 59/150\n",
      "32/32 - 0s - loss: 0.7101 - categorical_accuracy: 0.7130 - val_loss: 2.6443 - val_categorical_accuracy: 0.4005 - 469ms/epoch - 15ms/step\n",
      "Epoch 60/150\n",
      "32/32 - 0s - loss: 0.7045 - categorical_accuracy: 0.7120 - val_loss: 2.7541 - val_categorical_accuracy: 0.3634 - 465ms/epoch - 15ms/step\n",
      "Epoch 61/150\n",
      "32/32 - 0s - loss: 0.7025 - categorical_accuracy: 0.7090 - val_loss: 2.8394 - val_categorical_accuracy: 0.3773 - 465ms/epoch - 15ms/step\n",
      "Epoch 62/150\n",
      "32/32 - 0s - loss: 0.7012 - categorical_accuracy: 0.7150 - val_loss: 2.8240 - val_categorical_accuracy: 0.3819 - 464ms/epoch - 15ms/step\n",
      "Epoch 63/150\n",
      "32/32 - 0s - loss: 0.6572 - categorical_accuracy: 0.7358 - val_loss: 2.9350 - val_categorical_accuracy: 0.3542 - 457ms/epoch - 14ms/step\n",
      "Epoch 64/150\n",
      "32/32 - 0s - loss: 0.7636 - categorical_accuracy: 0.7061 - val_loss: 3.0915 - val_categorical_accuracy: 0.3796 - 473ms/epoch - 15ms/step\n",
      "Epoch 65/150\n",
      "32/32 - 0s - loss: 0.7138 - categorical_accuracy: 0.7120 - val_loss: 2.9556 - val_categorical_accuracy: 0.3611 - 473ms/epoch - 15ms/step\n",
      "Epoch 66/150\n",
      "32/32 - 0s - loss: 0.6765 - categorical_accuracy: 0.7210 - val_loss: 2.8658 - val_categorical_accuracy: 0.3750 - 467ms/epoch - 15ms/step\n",
      "Epoch 67/150\n",
      "32/32 - 0s - loss: 0.6921 - categorical_accuracy: 0.7090 - val_loss: 2.9622 - val_categorical_accuracy: 0.3241 - 465ms/epoch - 15ms/step\n",
      "Epoch 68/150\n",
      "32/32 - 0s - loss: 0.7022 - categorical_accuracy: 0.7160 - val_loss: 2.9504 - val_categorical_accuracy: 0.3588 - 472ms/epoch - 15ms/step\n",
      "Epoch 69/150\n",
      "32/32 - 0s - loss: 0.7100 - categorical_accuracy: 0.7061 - val_loss: 2.9340 - val_categorical_accuracy: 0.3657 - 466ms/epoch - 15ms/step\n",
      "Epoch 70/150\n",
      "32/32 - 0s - loss: 0.6614 - categorical_accuracy: 0.7190 - val_loss: 3.1826 - val_categorical_accuracy: 0.3935 - 482ms/epoch - 15ms/step\n",
      "Epoch 71/150\n",
      "32/32 - 0s - loss: 0.6472 - categorical_accuracy: 0.7299 - val_loss: 3.1732 - val_categorical_accuracy: 0.3449 - 489ms/epoch - 15ms/step\n",
      "Epoch 72/150\n",
      "32/32 - 1s - loss: 0.6376 - categorical_accuracy: 0.7219 - val_loss: 3.2782 - val_categorical_accuracy: 0.3356 - 516ms/epoch - 16ms/step\n",
      "Epoch 73/150\n",
      "32/32 - 0s - loss: 0.6084 - categorical_accuracy: 0.7458 - val_loss: 3.2401 - val_categorical_accuracy: 0.3912 - 478ms/epoch - 15ms/step\n",
      "Epoch 74/150\n",
      "32/32 - 0s - loss: 0.6069 - categorical_accuracy: 0.7368 - val_loss: 3.2026 - val_categorical_accuracy: 0.3750 - 460ms/epoch - 14ms/step\n",
      "Epoch 75/150\n",
      "32/32 - 0s - loss: 0.5936 - categorical_accuracy: 0.7418 - val_loss: 3.2362 - val_categorical_accuracy: 0.3426 - 444ms/epoch - 14ms/step\n",
      "Epoch 76/150\n",
      "32/32 - 0s - loss: 0.6530 - categorical_accuracy: 0.7349 - val_loss: 3.3330 - val_categorical_accuracy: 0.3403 - 449ms/epoch - 14ms/step\n",
      "Epoch 77/150\n",
      "32/32 - 0s - loss: 0.6455 - categorical_accuracy: 0.7239 - val_loss: 3.5598 - val_categorical_accuracy: 0.3333 - 464ms/epoch - 15ms/step\n",
      "Epoch 78/150\n",
      "32/32 - 0s - loss: 0.6317 - categorical_accuracy: 0.7388 - val_loss: 3.4637 - val_categorical_accuracy: 0.3843 - 457ms/epoch - 14ms/step\n",
      "Epoch 79/150\n",
      "32/32 - 0s - loss: 0.5866 - categorical_accuracy: 0.7507 - val_loss: 3.4200 - val_categorical_accuracy: 0.4051 - 460ms/epoch - 14ms/step\n",
      "Epoch 80/150\n",
      "32/32 - 0s - loss: 0.5965 - categorical_accuracy: 0.7418 - val_loss: 3.4378 - val_categorical_accuracy: 0.3403 - 476ms/epoch - 15ms/step\n",
      "Epoch 81/150\n",
      "32/32 - 0s - loss: 0.5787 - categorical_accuracy: 0.7597 - val_loss: 3.4205 - val_categorical_accuracy: 0.3449 - 473ms/epoch - 15ms/step\n",
      "Epoch 82/150\n",
      "32/32 - 0s - loss: 0.6377 - categorical_accuracy: 0.7229 - val_loss: 3.3645 - val_categorical_accuracy: 0.3634 - 464ms/epoch - 14ms/step\n",
      "Epoch 83/150\n",
      "32/32 - 0s - loss: 0.6516 - categorical_accuracy: 0.7358 - val_loss: 3.3495 - val_categorical_accuracy: 0.3657 - 468ms/epoch - 15ms/step\n",
      "Epoch 84/150\n",
      "32/32 - 0s - loss: 0.6047 - categorical_accuracy: 0.7378 - val_loss: 3.4609 - val_categorical_accuracy: 0.3704 - 451ms/epoch - 14ms/step\n",
      "Epoch 85/150\n",
      "32/32 - 0s - loss: 0.5675 - categorical_accuracy: 0.7716 - val_loss: 3.3983 - val_categorical_accuracy: 0.3727 - 456ms/epoch - 14ms/step\n",
      "Epoch 86/150\n",
      "32/32 - 0s - loss: 0.5732 - categorical_accuracy: 0.7507 - val_loss: 3.5278 - val_categorical_accuracy: 0.3588 - 453ms/epoch - 14ms/step\n",
      "Epoch 87/150\n",
      "32/32 - 0s - loss: 0.5513 - categorical_accuracy: 0.7786 - val_loss: 3.4597 - val_categorical_accuracy: 0.3588 - 462ms/epoch - 14ms/step\n",
      "Epoch 88/150\n",
      "32/32 - 0s - loss: 0.5450 - categorical_accuracy: 0.7557 - val_loss: 3.4305 - val_categorical_accuracy: 0.3727 - 468ms/epoch - 15ms/step\n",
      "Epoch 89/150\n",
      "32/32 - 0s - loss: 0.5365 - categorical_accuracy: 0.7716 - val_loss: 3.3806 - val_categorical_accuracy: 0.3634 - 453ms/epoch - 14ms/step\n",
      "Epoch 90/150\n",
      "32/32 - 0s - loss: 0.5344 - categorical_accuracy: 0.7776 - val_loss: 3.6182 - val_categorical_accuracy: 0.3565 - 495ms/epoch - 15ms/step\n",
      "Epoch 91/150\n",
      "32/32 - 0s - loss: 0.5269 - categorical_accuracy: 0.7706 - val_loss: 3.5549 - val_categorical_accuracy: 0.3542 - 463ms/epoch - 14ms/step\n",
      "Epoch 92/150\n",
      "32/32 - 0s - loss: 0.5191 - categorical_accuracy: 0.7696 - val_loss: 3.6072 - val_categorical_accuracy: 0.3565 - 457ms/epoch - 14ms/step\n",
      "Epoch 93/150\n",
      "32/32 - 0s - loss: 0.5337 - categorical_accuracy: 0.7627 - val_loss: 3.7674 - val_categorical_accuracy: 0.3542 - 455ms/epoch - 14ms/step\n",
      "Epoch 94/150\n",
      "32/32 - 0s - loss: 0.5509 - categorical_accuracy: 0.7656 - val_loss: 3.8032 - val_categorical_accuracy: 0.3519 - 465ms/epoch - 15ms/step\n",
      "Epoch 95/150\n",
      "32/32 - 0s - loss: 0.5045 - categorical_accuracy: 0.7666 - val_loss: 3.6957 - val_categorical_accuracy: 0.3634 - 467ms/epoch - 15ms/step\n",
      "Epoch 96/150\n",
      "32/32 - 0s - loss: 0.5195 - categorical_accuracy: 0.7795 - val_loss: 3.8715 - val_categorical_accuracy: 0.3866 - 459ms/epoch - 14ms/step\n",
      "Epoch 97/150\n",
      "32/32 - 0s - loss: 0.5240 - categorical_accuracy: 0.7726 - val_loss: 3.7223 - val_categorical_accuracy: 0.3542 - 457ms/epoch - 14ms/step\n",
      "Epoch 98/150\n",
      "32/32 - 0s - loss: 0.5394 - categorical_accuracy: 0.7756 - val_loss: 3.7832 - val_categorical_accuracy: 0.3889 - 473ms/epoch - 15ms/step\n",
      "Epoch 99/150\n",
      "32/32 - 0s - loss: 0.4789 - categorical_accuracy: 0.7974 - val_loss: 3.8922 - val_categorical_accuracy: 0.3380 - 466ms/epoch - 15ms/step\n",
      "Epoch 100/150\n",
      "32/32 - 0s - loss: 0.5115 - categorical_accuracy: 0.7795 - val_loss: 3.7502 - val_categorical_accuracy: 0.3704 - 471ms/epoch - 15ms/step\n",
      "Epoch 101/150\n",
      "32/32 - 0s - loss: 0.5137 - categorical_accuracy: 0.7746 - val_loss: 3.8424 - val_categorical_accuracy: 0.3657 - 461ms/epoch - 14ms/step\n",
      "Epoch 102/150\n",
      "32/32 - 0s - loss: 0.4919 - categorical_accuracy: 0.7815 - val_loss: 3.7715 - val_categorical_accuracy: 0.4005 - 459ms/epoch - 14ms/step\n",
      "Epoch 103/150\n",
      "32/32 - 0s - loss: 0.4774 - categorical_accuracy: 0.7875 - val_loss: 3.8267 - val_categorical_accuracy: 0.3681 - 474ms/epoch - 15ms/step\n",
      "Epoch 104/150\n",
      "32/32 - 0s - loss: 0.4568 - categorical_accuracy: 0.7885 - val_loss: 4.1991 - val_categorical_accuracy: 0.3426 - 475ms/epoch - 15ms/step\n",
      "Epoch 105/150\n",
      "32/32 - 0s - loss: 0.4794 - categorical_accuracy: 0.7905 - val_loss: 4.0427 - val_categorical_accuracy: 0.3588 - 462ms/epoch - 14ms/step\n",
      "Epoch 106/150\n",
      "32/32 - 0s - loss: 0.4616 - categorical_accuracy: 0.7934 - val_loss: 3.9865 - val_categorical_accuracy: 0.3634 - 499ms/epoch - 16ms/step\n",
      "Epoch 107/150\n",
      "32/32 - 1s - loss: 0.4843 - categorical_accuracy: 0.7915 - val_loss: 4.2156 - val_categorical_accuracy: 0.3426 - 553ms/epoch - 17ms/step\n",
      "Epoch 108/150\n",
      "32/32 - 0s - loss: 0.5040 - categorical_accuracy: 0.7815 - val_loss: 3.8610 - val_categorical_accuracy: 0.3542 - 495ms/epoch - 15ms/step\n",
      "Epoch 109/150\n",
      "32/32 - 0s - loss: 0.4979 - categorical_accuracy: 0.7855 - val_loss: 4.1460 - val_categorical_accuracy: 0.3634 - 464ms/epoch - 15ms/step\n",
      "Epoch 110/150\n",
      "32/32 - 0s - loss: 0.4694 - categorical_accuracy: 0.7954 - val_loss: 4.1558 - val_categorical_accuracy: 0.3588 - 461ms/epoch - 14ms/step\n",
      "Epoch 111/150\n",
      "32/32 - 0s - loss: 0.4645 - categorical_accuracy: 0.7815 - val_loss: 4.3419 - val_categorical_accuracy: 0.3310 - 447ms/epoch - 14ms/step\n",
      "Epoch 112/150\n",
      "32/32 - 0s - loss: 0.4586 - categorical_accuracy: 0.7815 - val_loss: 3.9997 - val_categorical_accuracy: 0.3866 - 442ms/epoch - 14ms/step\n",
      "Epoch 113/150\n",
      "32/32 - 0s - loss: 0.4530 - categorical_accuracy: 0.8004 - val_loss: 4.3595 - val_categorical_accuracy: 0.3380 - 450ms/epoch - 14ms/step\n",
      "Epoch 114/150\n",
      "32/32 - 0s - loss: 0.4674 - categorical_accuracy: 0.7786 - val_loss: 4.5059 - val_categorical_accuracy: 0.3796 - 453ms/epoch - 14ms/step\n",
      "Epoch 115/150\n",
      "32/32 - 0s - loss: 0.4537 - categorical_accuracy: 0.7984 - val_loss: 4.4591 - val_categorical_accuracy: 0.3773 - 458ms/epoch - 14ms/step\n",
      "Epoch 116/150\n",
      "32/32 - 0s - loss: 0.4288 - categorical_accuracy: 0.8123 - val_loss: 4.5675 - val_categorical_accuracy: 0.3495 - 449ms/epoch - 14ms/step\n",
      "Epoch 117/150\n",
      "32/32 - 0s - loss: 0.4841 - categorical_accuracy: 0.7786 - val_loss: 4.7282 - val_categorical_accuracy: 0.3611 - 450ms/epoch - 14ms/step\n",
      "Epoch 118/150\n",
      "32/32 - 0s - loss: 0.4538 - categorical_accuracy: 0.8004 - val_loss: 4.8544 - val_categorical_accuracy: 0.3380 - 450ms/epoch - 14ms/step\n",
      "Epoch 119/150\n",
      "32/32 - 0s - loss: 0.5100 - categorical_accuracy: 0.7805 - val_loss: 4.2391 - val_categorical_accuracy: 0.3333 - 455ms/epoch - 14ms/step\n",
      "Epoch 120/150\n",
      "32/32 - 0s - loss: 0.4589 - categorical_accuracy: 0.7925 - val_loss: 4.2804 - val_categorical_accuracy: 0.3750 - 457ms/epoch - 14ms/step\n",
      "Epoch 121/150\n",
      "32/32 - 0s - loss: 0.4296 - categorical_accuracy: 0.8064 - val_loss: 4.3572 - val_categorical_accuracy: 0.3681 - 460ms/epoch - 14ms/step\n",
      "Epoch 122/150\n",
      "32/32 - 0s - loss: 0.4387 - categorical_accuracy: 0.7954 - val_loss: 4.4440 - val_categorical_accuracy: 0.3588 - 463ms/epoch - 14ms/step\n",
      "Epoch 123/150\n",
      "32/32 - 0s - loss: 0.4630 - categorical_accuracy: 0.7994 - val_loss: 4.4573 - val_categorical_accuracy: 0.3495 - 462ms/epoch - 14ms/step\n",
      "Epoch 124/150\n",
      "32/32 - 0s - loss: 0.4375 - categorical_accuracy: 0.7984 - val_loss: 4.2644 - val_categorical_accuracy: 0.3542 - 458ms/epoch - 14ms/step\n",
      "Epoch 125/150\n",
      "32/32 - 0s - loss: 0.4280 - categorical_accuracy: 0.7885 - val_loss: 4.4017 - val_categorical_accuracy: 0.3426 - 459ms/epoch - 14ms/step\n",
      "Epoch 126/150\n",
      "32/32 - 0s - loss: 0.4258 - categorical_accuracy: 0.7974 - val_loss: 4.7514 - val_categorical_accuracy: 0.3773 - 453ms/epoch - 14ms/step\n",
      "Epoch 127/150\n",
      "32/32 - 0s - loss: 0.4501 - categorical_accuracy: 0.7845 - val_loss: 4.3264 - val_categorical_accuracy: 0.3333 - 454ms/epoch - 14ms/step\n",
      "Epoch 128/150\n",
      "32/32 - 0s - loss: 0.4442 - categorical_accuracy: 0.7855 - val_loss: 5.0720 - val_categorical_accuracy: 0.3449 - 454ms/epoch - 14ms/step\n",
      "Epoch 129/150\n",
      "32/32 - 0s - loss: 0.4309 - categorical_accuracy: 0.8083 - val_loss: 4.4909 - val_categorical_accuracy: 0.3657 - 458ms/epoch - 14ms/step\n",
      "Epoch 130/150\n",
      "32/32 - 0s - loss: 0.4297 - categorical_accuracy: 0.7994 - val_loss: 4.5625 - val_categorical_accuracy: 0.3310 - 460ms/epoch - 14ms/step\n",
      "Epoch 131/150\n",
      "32/32 - 0s - loss: 0.4184 - categorical_accuracy: 0.8113 - val_loss: 4.4347 - val_categorical_accuracy: 0.3611 - 453ms/epoch - 14ms/step\n",
      "Epoch 132/150\n",
      "32/32 - 0s - loss: 0.4374 - categorical_accuracy: 0.8014 - val_loss: 4.5104 - val_categorical_accuracy: 0.3611 - 464ms/epoch - 14ms/step\n",
      "Epoch 133/150\n",
      "32/32 - 0s - loss: 0.4004 - categorical_accuracy: 0.8113 - val_loss: 4.5884 - val_categorical_accuracy: 0.3565 - 480ms/epoch - 15ms/step\n",
      "Epoch 134/150\n",
      "32/32 - 0s - loss: 0.4395 - categorical_accuracy: 0.8083 - val_loss: 4.5508 - val_categorical_accuracy: 0.3634 - 476ms/epoch - 15ms/step\n",
      "Epoch 135/150\n",
      "32/32 - 0s - loss: 0.4111 - categorical_accuracy: 0.8143 - val_loss: 4.4782 - val_categorical_accuracy: 0.3519 - 455ms/epoch - 14ms/step\n",
      "Epoch 136/150\n",
      "32/32 - 0s - loss: 0.3787 - categorical_accuracy: 0.8222 - val_loss: 4.6141 - val_categorical_accuracy: 0.3843 - 461ms/epoch - 14ms/step\n",
      "Epoch 137/150\n",
      "32/32 - 0s - loss: 0.4137 - categorical_accuracy: 0.8173 - val_loss: 4.7421 - val_categorical_accuracy: 0.3403 - 460ms/epoch - 14ms/step\n",
      "Epoch 138/150\n",
      "32/32 - 0s - loss: 0.3870 - categorical_accuracy: 0.8193 - val_loss: 5.0316 - val_categorical_accuracy: 0.3588 - 462ms/epoch - 14ms/step\n",
      "Epoch 139/150\n",
      "32/32 - 0s - loss: 0.3794 - categorical_accuracy: 0.8123 - val_loss: 4.9016 - val_categorical_accuracy: 0.3426 - 475ms/epoch - 15ms/step\n",
      "Epoch 140/150\n",
      "32/32 - 0s - loss: 0.4068 - categorical_accuracy: 0.8203 - val_loss: 4.8311 - val_categorical_accuracy: 0.3472 - 462ms/epoch - 14ms/step\n",
      "Epoch 141/150\n",
      "32/32 - 0s - loss: 0.4011 - categorical_accuracy: 0.8073 - val_loss: 5.1382 - val_categorical_accuracy: 0.3403 - 458ms/epoch - 14ms/step\n",
      "Epoch 142/150\n",
      "32/32 - 0s - loss: 0.3792 - categorical_accuracy: 0.8183 - val_loss: 4.7998 - val_categorical_accuracy: 0.3588 - 466ms/epoch - 15ms/step\n",
      "Epoch 143/150\n",
      "32/32 - 0s - loss: 0.3711 - categorical_accuracy: 0.8183 - val_loss: 4.9556 - val_categorical_accuracy: 0.4213 - 488ms/epoch - 15ms/step\n",
      "Epoch 144/150\n",
      "32/32 - 0s - loss: 0.3854 - categorical_accuracy: 0.8123 - val_loss: 5.0506 - val_categorical_accuracy: 0.3681 - 493ms/epoch - 15ms/step\n",
      "Epoch 145/150\n",
      "32/32 - 0s - loss: 0.4146 - categorical_accuracy: 0.8073 - val_loss: 5.0249 - val_categorical_accuracy: 0.3704 - 493ms/epoch - 15ms/step\n",
      "Epoch 146/150\n",
      "32/32 - 0s - loss: 0.4419 - categorical_accuracy: 0.8044 - val_loss: 5.0447 - val_categorical_accuracy: 0.3380 - 469ms/epoch - 15ms/step\n",
      "Epoch 147/150\n",
      "32/32 - 0s - loss: 0.4893 - categorical_accuracy: 0.8034 - val_loss: 4.9137 - val_categorical_accuracy: 0.3958 - 447ms/epoch - 14ms/step\n",
      "Epoch 148/150\n",
      "32/32 - 0s - loss: 0.4039 - categorical_accuracy: 0.8232 - val_loss: 4.9539 - val_categorical_accuracy: 0.4190 - 438ms/epoch - 14ms/step\n",
      "Epoch 149/150\n",
      "32/32 - 0s - loss: 0.3800 - categorical_accuracy: 0.8222 - val_loss: 4.8424 - val_categorical_accuracy: 0.3495 - 439ms/epoch - 14ms/step\n",
      "Epoch 150/150\n",
      "32/32 - 0s - loss: 0.3853 - categorical_accuracy: 0.8064 - val_loss: 4.9970 - val_categorical_accuracy: 0.3588 - 437ms/epoch - 14ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2   3   0   3   0   4   0   1   1]\n",
      " [ 10 112   7   9   2  29   5   7   8]\n",
      " [  0  18   6   5   0   0   3   2   1]\n",
      " [  2  11  12  11   3   0   4   5   4]\n",
      " [  0   1   0   2   2   1   3   3   3]\n",
      " [  2   6   1   0   0   1   1   1   2]\n",
      " [  3   8   4   5   3   2   7   8   3]\n",
      " [  0   4   3   4   4   1  10   6   4]\n",
      " [  3   7   2   3   1   0   5   5   8]]\n",
      ">#2: 35.880\n",
      "Epoch 1/150\n",
      "32/32 - 1s - loss: 2.1785 - categorical_accuracy: 0.2582 - val_loss: 2.0807 - val_categorical_accuracy: 0.2477 - 691ms/epoch - 22ms/step\n",
      "Epoch 2/150\n",
      "32/32 - 0s - loss: 2.0183 - categorical_accuracy: 0.2989 - val_loss: 1.8227 - val_categorical_accuracy: 0.3611 - 441ms/epoch - 14ms/step\n",
      "Epoch 3/150\n",
      "32/32 - 0s - loss: 1.9059 - categorical_accuracy: 0.2910 - val_loss: 1.9221 - val_categorical_accuracy: 0.2292 - 447ms/epoch - 14ms/step\n",
      "Epoch 4/150\n",
      "32/32 - 0s - loss: 1.8787 - categorical_accuracy: 0.2830 - val_loss: 1.7490 - val_categorical_accuracy: 0.3032 - 436ms/epoch - 14ms/step\n",
      "Epoch 5/150\n",
      "32/32 - 0s - loss: 1.8033 - categorical_accuracy: 0.3088 - val_loss: 1.7571 - val_categorical_accuracy: 0.3542 - 441ms/epoch - 14ms/step\n",
      "Epoch 6/150\n",
      "32/32 - 0s - loss: 1.7373 - categorical_accuracy: 0.3188 - val_loss: 1.9741 - val_categorical_accuracy: 0.2708 - 438ms/epoch - 14ms/step\n",
      "Epoch 7/150\n",
      "32/32 - 0s - loss: 1.6934 - categorical_accuracy: 0.3704 - val_loss: 1.6390 - val_categorical_accuracy: 0.4120 - 443ms/epoch - 14ms/step\n",
      "Epoch 8/150\n",
      "32/32 - 0s - loss: 1.6127 - categorical_accuracy: 0.3714 - val_loss: 1.6852 - val_categorical_accuracy: 0.3380 - 439ms/epoch - 14ms/step\n",
      "Epoch 9/150\n",
      "32/32 - 0s - loss: 1.5980 - categorical_accuracy: 0.3714 - val_loss: 1.7503 - val_categorical_accuracy: 0.3125 - 446ms/epoch - 14ms/step\n",
      "Epoch 10/150\n",
      "32/32 - 0s - loss: 1.5703 - categorical_accuracy: 0.4220 - val_loss: 1.8657 - val_categorical_accuracy: 0.2384 - 444ms/epoch - 14ms/step\n",
      "Epoch 11/150\n",
      "32/32 - 0s - loss: 1.5996 - categorical_accuracy: 0.3843 - val_loss: 1.8017 - val_categorical_accuracy: 0.3241 - 447ms/epoch - 14ms/step\n",
      "Epoch 12/150\n",
      "32/32 - 0s - loss: 1.5496 - categorical_accuracy: 0.4280 - val_loss: 1.7168 - val_categorical_accuracy: 0.3426 - 444ms/epoch - 14ms/step\n",
      "Epoch 13/150\n",
      "32/32 - 0s - loss: 1.4731 - categorical_accuracy: 0.4191 - val_loss: 1.8606 - val_categorical_accuracy: 0.2731 - 438ms/epoch - 14ms/step\n",
      "Epoch 14/150\n",
      "32/32 - 0s - loss: 1.4946 - categorical_accuracy: 0.4667 - val_loss: 1.7848 - val_categorical_accuracy: 0.2963 - 440ms/epoch - 14ms/step\n",
      "Epoch 15/150\n",
      "32/32 - 0s - loss: 1.4089 - categorical_accuracy: 0.4588 - val_loss: 1.7838 - val_categorical_accuracy: 0.3565 - 438ms/epoch - 14ms/step\n",
      "Epoch 16/150\n",
      "32/32 - 0s - loss: 1.3738 - categorical_accuracy: 0.4916 - val_loss: 1.9430 - val_categorical_accuracy: 0.2940 - 441ms/epoch - 14ms/step\n",
      "Epoch 17/150\n",
      "32/32 - 0s - loss: 1.3756 - categorical_accuracy: 0.4528 - val_loss: 1.8650 - val_categorical_accuracy: 0.3079 - 435ms/epoch - 14ms/step\n",
      "Epoch 18/150\n",
      "32/32 - 0s - loss: 1.3601 - categorical_accuracy: 0.4846 - val_loss: 1.8650 - val_categorical_accuracy: 0.3241 - 448ms/epoch - 14ms/step\n",
      "Epoch 19/150\n",
      "32/32 - 0s - loss: 1.3433 - categorical_accuracy: 0.4906 - val_loss: 1.6452 - val_categorical_accuracy: 0.4421 - 443ms/epoch - 14ms/step\n",
      "Epoch 20/150\n",
      "32/32 - 0s - loss: 1.2646 - categorical_accuracy: 0.5233 - val_loss: 1.7898 - val_categorical_accuracy: 0.3449 - 443ms/epoch - 14ms/step\n",
      "Epoch 21/150\n",
      "32/32 - 0s - loss: 1.2790 - categorical_accuracy: 0.5094 - val_loss: 1.6825 - val_categorical_accuracy: 0.4074 - 442ms/epoch - 14ms/step\n",
      "Epoch 22/150\n",
      "32/32 - 0s - loss: 1.2620 - categorical_accuracy: 0.5124 - val_loss: 1.7429 - val_categorical_accuracy: 0.3981 - 441ms/epoch - 14ms/step\n",
      "Epoch 23/150\n",
      "32/32 - 0s - loss: 1.2952 - categorical_accuracy: 0.5283 - val_loss: 2.0020 - val_categorical_accuracy: 0.3565 - 440ms/epoch - 14ms/step\n",
      "Epoch 24/150\n",
      "32/32 - 0s - loss: 1.2371 - categorical_accuracy: 0.5432 - val_loss: 1.8816 - val_categorical_accuracy: 0.3403 - 443ms/epoch - 14ms/step\n",
      "Epoch 25/150\n",
      "32/32 - 0s - loss: 1.1872 - categorical_accuracy: 0.5333 - val_loss: 2.0041 - val_categorical_accuracy: 0.3218 - 439ms/epoch - 14ms/step\n",
      "Epoch 26/150\n",
      "32/32 - 0s - loss: 1.1471 - categorical_accuracy: 0.5571 - val_loss: 1.8249 - val_categorical_accuracy: 0.3727 - 446ms/epoch - 14ms/step\n",
      "Epoch 27/150\n",
      "32/32 - 0s - loss: 1.1243 - categorical_accuracy: 0.5492 - val_loss: 1.9470 - val_categorical_accuracy: 0.3403 - 443ms/epoch - 14ms/step\n",
      "Epoch 28/150\n",
      "32/32 - 0s - loss: 1.1444 - categorical_accuracy: 0.5591 - val_loss: 1.9722 - val_categorical_accuracy: 0.3449 - 442ms/epoch - 14ms/step\n",
      "Epoch 29/150\n",
      "32/32 - 0s - loss: 1.1171 - categorical_accuracy: 0.5621 - val_loss: 1.9384 - val_categorical_accuracy: 0.3681 - 440ms/epoch - 14ms/step\n",
      "Epoch 30/150\n",
      "32/32 - 0s - loss: 1.1184 - categorical_accuracy: 0.6058 - val_loss: 1.9509 - val_categorical_accuracy: 0.3657 - 447ms/epoch - 14ms/step\n",
      "Epoch 31/150\n",
      "32/32 - 0s - loss: 1.0775 - categorical_accuracy: 0.5690 - val_loss: 2.0713 - val_categorical_accuracy: 0.3380 - 447ms/epoch - 14ms/step\n",
      "Epoch 32/150\n",
      "32/32 - 0s - loss: 1.1274 - categorical_accuracy: 0.5670 - val_loss: 2.0562 - val_categorical_accuracy: 0.3565 - 442ms/epoch - 14ms/step\n",
      "Epoch 33/150\n",
      "32/32 - 0s - loss: 1.0395 - categorical_accuracy: 0.6117 - val_loss: 1.9346 - val_categorical_accuracy: 0.4468 - 444ms/epoch - 14ms/step\n",
      "Epoch 34/150\n",
      "32/32 - 0s - loss: 1.0294 - categorical_accuracy: 0.5948 - val_loss: 1.9123 - val_categorical_accuracy: 0.4236 - 443ms/epoch - 14ms/step\n",
      "Epoch 35/150\n",
      "32/32 - 0s - loss: 1.0294 - categorical_accuracy: 0.5899 - val_loss: 2.2226 - val_categorical_accuracy: 0.3194 - 438ms/epoch - 14ms/step\n",
      "Epoch 36/150\n",
      "32/32 - 0s - loss: 0.9930 - categorical_accuracy: 0.6038 - val_loss: 2.1557 - val_categorical_accuracy: 0.3611 - 446ms/epoch - 14ms/step\n",
      "Epoch 37/150\n",
      "32/32 - 0s - loss: 0.9719 - categorical_accuracy: 0.6177 - val_loss: 2.1535 - val_categorical_accuracy: 0.3519 - 454ms/epoch - 14ms/step\n",
      "Epoch 38/150\n",
      "32/32 - 0s - loss: 0.9783 - categorical_accuracy: 0.6177 - val_loss: 2.2832 - val_categorical_accuracy: 0.3843 - 440ms/epoch - 14ms/step\n",
      "Epoch 39/150\n",
      "32/32 - 0s - loss: 1.0350 - categorical_accuracy: 0.6127 - val_loss: 2.2694 - val_categorical_accuracy: 0.3634 - 444ms/epoch - 14ms/step\n",
      "Epoch 40/150\n",
      "32/32 - 0s - loss: 0.9791 - categorical_accuracy: 0.6276 - val_loss: 2.2434 - val_categorical_accuracy: 0.3403 - 439ms/epoch - 14ms/step\n",
      "Epoch 41/150\n",
      "32/32 - 0s - loss: 0.9539 - categorical_accuracy: 0.6296 - val_loss: 2.2722 - val_categorical_accuracy: 0.3380 - 440ms/epoch - 14ms/step\n",
      "Epoch 42/150\n",
      "32/32 - 0s - loss: 0.9836 - categorical_accuracy: 0.6266 - val_loss: 2.0902 - val_categorical_accuracy: 0.3935 - 444ms/epoch - 14ms/step\n",
      "Epoch 43/150\n",
      "32/32 - 0s - loss: 0.9055 - categorical_accuracy: 0.6375 - val_loss: 2.2249 - val_categorical_accuracy: 0.3773 - 442ms/epoch - 14ms/step\n",
      "Epoch 44/150\n",
      "32/32 - 0s - loss: 0.8834 - categorical_accuracy: 0.6614 - val_loss: 2.2151 - val_categorical_accuracy: 0.4236 - 456ms/epoch - 14ms/step\n",
      "Epoch 45/150\n",
      "32/32 - 0s - loss: 0.8581 - categorical_accuracy: 0.6673 - val_loss: 2.1384 - val_categorical_accuracy: 0.4907 - 447ms/epoch - 14ms/step\n",
      "Epoch 46/150\n",
      "32/32 - 0s - loss: 0.8752 - categorical_accuracy: 0.6783 - val_loss: 2.3280 - val_categorical_accuracy: 0.4005 - 440ms/epoch - 14ms/step\n",
      "Epoch 47/150\n",
      "32/32 - 0s - loss: 0.8898 - categorical_accuracy: 0.6296 - val_loss: 2.3591 - val_categorical_accuracy: 0.3657 - 448ms/epoch - 14ms/step\n",
      "Epoch 48/150\n",
      "32/32 - 0s - loss: 0.9009 - categorical_accuracy: 0.6634 - val_loss: 2.4133 - val_categorical_accuracy: 0.4120 - 449ms/epoch - 14ms/step\n",
      "Epoch 49/150\n",
      "32/32 - 0s - loss: 0.8815 - categorical_accuracy: 0.6604 - val_loss: 2.5289 - val_categorical_accuracy: 0.3241 - 448ms/epoch - 14ms/step\n",
      "Epoch 50/150\n",
      "32/32 - 0s - loss: 0.8256 - categorical_accuracy: 0.6783 - val_loss: 2.3988 - val_categorical_accuracy: 0.4005 - 447ms/epoch - 14ms/step\n",
      "Epoch 51/150\n",
      "32/32 - 0s - loss: 0.8374 - categorical_accuracy: 0.6703 - val_loss: 2.4184 - val_categorical_accuracy: 0.3634 - 443ms/epoch - 14ms/step\n",
      "Epoch 52/150\n",
      "32/32 - 0s - loss: 0.8711 - categorical_accuracy: 0.6316 - val_loss: 2.3704 - val_categorical_accuracy: 0.3819 - 446ms/epoch - 14ms/step\n",
      "Epoch 53/150\n",
      "32/32 - 0s - loss: 0.8994 - categorical_accuracy: 0.6584 - val_loss: 2.2778 - val_categorical_accuracy: 0.4213 - 437ms/epoch - 14ms/step\n",
      "Epoch 54/150\n",
      "32/32 - 0s - loss: 0.8219 - categorical_accuracy: 0.6882 - val_loss: 2.5643 - val_categorical_accuracy: 0.4051 - 444ms/epoch - 14ms/step\n",
      "Epoch 55/150\n",
      "32/32 - 0s - loss: 0.7843 - categorical_accuracy: 0.6892 - val_loss: 2.4574 - val_categorical_accuracy: 0.3773 - 444ms/epoch - 14ms/step\n",
      "Epoch 56/150\n",
      "32/32 - 0s - loss: 0.8695 - categorical_accuracy: 0.6713 - val_loss: 2.3473 - val_categorical_accuracy: 0.4074 - 440ms/epoch - 14ms/step\n",
      "Epoch 57/150\n",
      "32/32 - 0s - loss: 0.7760 - categorical_accuracy: 0.7011 - val_loss: 2.4472 - val_categorical_accuracy: 0.3912 - 449ms/epoch - 14ms/step\n",
      "Epoch 58/150\n",
      "32/32 - 0s - loss: 0.7697 - categorical_accuracy: 0.6961 - val_loss: 2.5410 - val_categorical_accuracy: 0.4028 - 446ms/epoch - 14ms/step\n",
      "Epoch 59/150\n",
      "32/32 - 0s - loss: 0.8167 - categorical_accuracy: 0.6872 - val_loss: 2.5666 - val_categorical_accuracy: 0.3750 - 445ms/epoch - 14ms/step\n",
      "Epoch 60/150\n",
      "32/32 - 0s - loss: 1.0321 - categorical_accuracy: 0.6495 - val_loss: 2.2195 - val_categorical_accuracy: 0.4144 - 450ms/epoch - 14ms/step\n",
      "Epoch 61/150\n",
      "32/32 - 0s - loss: 0.8390 - categorical_accuracy: 0.7001 - val_loss: 2.3295 - val_categorical_accuracy: 0.4051 - 449ms/epoch - 14ms/step\n",
      "Epoch 62/150\n",
      "32/32 - 0s - loss: 0.7645 - categorical_accuracy: 0.6912 - val_loss: 2.4355 - val_categorical_accuracy: 0.4097 - 457ms/epoch - 14ms/step\n",
      "Epoch 63/150\n",
      "32/32 - 0s - loss: 0.7649 - categorical_accuracy: 0.6922 - val_loss: 2.4350 - val_categorical_accuracy: 0.4167 - 466ms/epoch - 15ms/step\n",
      "Epoch 64/150\n",
      "32/32 - 0s - loss: 0.7470 - categorical_accuracy: 0.7090 - val_loss: 2.4640 - val_categorical_accuracy: 0.4051 - 456ms/epoch - 14ms/step\n",
      "Epoch 65/150\n",
      "32/32 - 0s - loss: 0.7262 - categorical_accuracy: 0.7180 - val_loss: 2.6274 - val_categorical_accuracy: 0.3727 - 442ms/epoch - 14ms/step\n",
      "Epoch 66/150\n",
      "32/32 - 0s - loss: 0.7113 - categorical_accuracy: 0.7239 - val_loss: 2.6691 - val_categorical_accuracy: 0.3819 - 438ms/epoch - 14ms/step\n",
      "Epoch 67/150\n",
      "32/32 - 0s - loss: 0.7571 - categorical_accuracy: 0.6842 - val_loss: 2.7781 - val_categorical_accuracy: 0.3657 - 436ms/epoch - 14ms/step\n",
      "Epoch 68/150\n",
      "32/32 - 0s - loss: 0.7014 - categorical_accuracy: 0.7249 - val_loss: 2.7410 - val_categorical_accuracy: 0.3657 - 443ms/epoch - 14ms/step\n",
      "Epoch 69/150\n",
      "32/32 - 0s - loss: 0.7304 - categorical_accuracy: 0.6912 - val_loss: 2.7428 - val_categorical_accuracy: 0.3657 - 443ms/epoch - 14ms/step\n",
      "Epoch 70/150\n",
      "32/32 - 0s - loss: 0.7138 - categorical_accuracy: 0.7170 - val_loss: 2.7491 - val_categorical_accuracy: 0.4005 - 446ms/epoch - 14ms/step\n",
      "Epoch 71/150\n",
      "32/32 - 0s - loss: 0.6922 - categorical_accuracy: 0.7219 - val_loss: 2.8938 - val_categorical_accuracy: 0.3681 - 439ms/epoch - 14ms/step\n",
      "Epoch 72/150\n",
      "32/32 - 0s - loss: 0.6506 - categorical_accuracy: 0.7339 - val_loss: 2.8493 - val_categorical_accuracy: 0.3958 - 439ms/epoch - 14ms/step\n",
      "Epoch 73/150\n",
      "32/32 - 0s - loss: 0.6636 - categorical_accuracy: 0.7279 - val_loss: 2.8484 - val_categorical_accuracy: 0.3981 - 437ms/epoch - 14ms/step\n",
      "Epoch 74/150\n",
      "32/32 - 0s - loss: 0.6550 - categorical_accuracy: 0.7378 - val_loss: 3.0906 - val_categorical_accuracy: 0.3681 - 437ms/epoch - 14ms/step\n",
      "Epoch 75/150\n",
      "32/32 - 0s - loss: 0.6682 - categorical_accuracy: 0.7428 - val_loss: 2.9641 - val_categorical_accuracy: 0.3958 - 439ms/epoch - 14ms/step\n",
      "Epoch 76/150\n",
      "32/32 - 0s - loss: 0.6465 - categorical_accuracy: 0.7438 - val_loss: 2.9885 - val_categorical_accuracy: 0.3912 - 439ms/epoch - 14ms/step\n",
      "Epoch 77/150\n",
      "32/32 - 0s - loss: 0.6708 - categorical_accuracy: 0.7140 - val_loss: 3.0286 - val_categorical_accuracy: 0.3310 - 464ms/epoch - 14ms/step\n",
      "Epoch 78/150\n",
      "32/32 - 0s - loss: 0.6739 - categorical_accuracy: 0.7349 - val_loss: 3.0453 - val_categorical_accuracy: 0.3750 - 441ms/epoch - 14ms/step\n",
      "Epoch 79/150\n",
      "32/32 - 0s - loss: 0.6495 - categorical_accuracy: 0.7458 - val_loss: 2.8263 - val_categorical_accuracy: 0.3657 - 443ms/epoch - 14ms/step\n",
      "Epoch 80/150\n",
      "32/32 - 0s - loss: 0.6344 - categorical_accuracy: 0.7180 - val_loss: 2.9514 - val_categorical_accuracy: 0.4190 - 439ms/epoch - 14ms/step\n",
      "Epoch 81/150\n",
      "32/32 - 0s - loss: 0.6277 - categorical_accuracy: 0.7498 - val_loss: 3.0622 - val_categorical_accuracy: 0.3542 - 438ms/epoch - 14ms/step\n",
      "Epoch 82/150\n",
      "32/32 - 0s - loss: 0.6448 - categorical_accuracy: 0.7438 - val_loss: 2.9588 - val_categorical_accuracy: 0.4005 - 437ms/epoch - 14ms/step\n",
      "Epoch 83/150\n",
      "32/32 - 0s - loss: 0.6191 - categorical_accuracy: 0.7617 - val_loss: 3.1230 - val_categorical_accuracy: 0.3889 - 440ms/epoch - 14ms/step\n",
      "Epoch 84/150\n",
      "32/32 - 0s - loss: 0.6210 - categorical_accuracy: 0.7547 - val_loss: 3.1343 - val_categorical_accuracy: 0.3588 - 438ms/epoch - 14ms/step\n",
      "Epoch 85/150\n",
      "32/32 - 0s - loss: 0.6056 - categorical_accuracy: 0.7507 - val_loss: 3.2785 - val_categorical_accuracy: 0.3542 - 439ms/epoch - 14ms/step\n",
      "Epoch 86/150\n",
      "32/32 - 0s - loss: 0.6095 - categorical_accuracy: 0.7468 - val_loss: 3.5359 - val_categorical_accuracy: 0.3588 - 438ms/epoch - 14ms/step\n",
      "Epoch 87/150\n",
      "32/32 - 0s - loss: 0.6207 - categorical_accuracy: 0.7517 - val_loss: 3.1633 - val_categorical_accuracy: 0.3935 - 447ms/epoch - 14ms/step\n",
      "Epoch 88/150\n",
      "32/32 - 0s - loss: 0.5826 - categorical_accuracy: 0.7666 - val_loss: 3.0547 - val_categorical_accuracy: 0.3889 - 439ms/epoch - 14ms/step\n",
      "Epoch 89/150\n",
      "32/32 - 0s - loss: 0.5775 - categorical_accuracy: 0.7696 - val_loss: 3.2548 - val_categorical_accuracy: 0.4028 - 440ms/epoch - 14ms/step\n",
      "Epoch 90/150\n",
      "32/32 - 0s - loss: 0.5958 - categorical_accuracy: 0.7537 - val_loss: 3.1517 - val_categorical_accuracy: 0.3727 - 442ms/epoch - 14ms/step\n",
      "Epoch 91/150\n",
      "32/32 - 0s - loss: 0.5860 - categorical_accuracy: 0.7488 - val_loss: 3.2921 - val_categorical_accuracy: 0.3542 - 444ms/epoch - 14ms/step\n",
      "Epoch 92/150\n",
      "32/32 - 0s - loss: 0.5893 - categorical_accuracy: 0.7597 - val_loss: 3.2177 - val_categorical_accuracy: 0.3634 - 443ms/epoch - 14ms/step\n",
      "Epoch 93/150\n",
      "32/32 - 0s - loss: 0.5698 - categorical_accuracy: 0.7577 - val_loss: 3.2739 - val_categorical_accuracy: 0.3519 - 440ms/epoch - 14ms/step\n",
      "Epoch 94/150\n",
      "32/32 - 0s - loss: 0.5757 - categorical_accuracy: 0.7686 - val_loss: 3.0806 - val_categorical_accuracy: 0.3866 - 444ms/epoch - 14ms/step\n",
      "Epoch 95/150\n",
      "32/32 - 0s - loss: 0.5607 - categorical_accuracy: 0.7557 - val_loss: 3.2652 - val_categorical_accuracy: 0.3657 - 440ms/epoch - 14ms/step\n",
      "Epoch 96/150\n",
      "32/32 - 0s - loss: 0.5458 - categorical_accuracy: 0.7805 - val_loss: 3.5870 - val_categorical_accuracy: 0.3565 - 433ms/epoch - 14ms/step\n",
      "Epoch 97/150\n",
      "32/32 - 0s - loss: 0.5245 - categorical_accuracy: 0.7676 - val_loss: 3.4635 - val_categorical_accuracy: 0.3796 - 434ms/epoch - 14ms/step\n",
      "Epoch 98/150\n",
      "32/32 - 0s - loss: 0.5378 - categorical_accuracy: 0.7686 - val_loss: 3.6124 - val_categorical_accuracy: 0.4236 - 450ms/epoch - 14ms/step\n",
      "Epoch 99/150\n",
      "32/32 - 0s - loss: 0.5448 - categorical_accuracy: 0.7617 - val_loss: 3.4553 - val_categorical_accuracy: 0.3912 - 435ms/epoch - 14ms/step\n",
      "Epoch 100/150\n",
      "32/32 - 0s - loss: 0.5616 - categorical_accuracy: 0.7547 - val_loss: 3.5514 - val_categorical_accuracy: 0.3727 - 436ms/epoch - 14ms/step\n",
      "Epoch 101/150\n",
      "32/32 - 0s - loss: 0.5731 - categorical_accuracy: 0.7448 - val_loss: 3.4826 - val_categorical_accuracy: 0.3588 - 439ms/epoch - 14ms/step\n",
      "Epoch 102/150\n",
      "32/32 - 0s - loss: 0.5236 - categorical_accuracy: 0.7786 - val_loss: 3.4518 - val_categorical_accuracy: 0.3611 - 444ms/epoch - 14ms/step\n",
      "Epoch 103/150\n",
      "32/32 - 0s - loss: 0.5268 - categorical_accuracy: 0.7676 - val_loss: 3.5327 - val_categorical_accuracy: 0.3681 - 439ms/epoch - 14ms/step\n",
      "Epoch 104/150\n",
      "32/32 - 0s - loss: 0.5602 - categorical_accuracy: 0.7567 - val_loss: 3.4182 - val_categorical_accuracy: 0.3935 - 437ms/epoch - 14ms/step\n",
      "Epoch 105/150\n",
      "32/32 - 0s - loss: 0.5000 - categorical_accuracy: 0.7865 - val_loss: 3.3706 - val_categorical_accuracy: 0.3796 - 439ms/epoch - 14ms/step\n",
      "Epoch 106/150\n",
      "32/32 - 0s - loss: 0.5590 - categorical_accuracy: 0.7567 - val_loss: 3.3413 - val_categorical_accuracy: 0.3889 - 440ms/epoch - 14ms/step\n",
      "Epoch 107/150\n",
      "32/32 - 0s - loss: 0.5592 - categorical_accuracy: 0.7498 - val_loss: 3.3379 - val_categorical_accuracy: 0.4005 - 441ms/epoch - 14ms/step\n",
      "Epoch 108/150\n",
      "32/32 - 0s - loss: 0.4917 - categorical_accuracy: 0.7805 - val_loss: 3.4889 - val_categorical_accuracy: 0.3981 - 441ms/epoch - 14ms/step\n",
      "Epoch 109/150\n",
      "32/32 - 0s - loss: 0.5214 - categorical_accuracy: 0.7607 - val_loss: 3.5359 - val_categorical_accuracy: 0.3750 - 448ms/epoch - 14ms/step\n",
      "Epoch 110/150\n",
      "32/32 - 0s - loss: 0.5730 - categorical_accuracy: 0.7478 - val_loss: 3.4458 - val_categorical_accuracy: 0.3912 - 443ms/epoch - 14ms/step\n",
      "Epoch 111/150\n",
      "32/32 - 0s - loss: 0.5301 - categorical_accuracy: 0.7716 - val_loss: 3.4564 - val_categorical_accuracy: 0.4028 - 435ms/epoch - 14ms/step\n",
      "Epoch 112/150\n",
      "32/32 - 0s - loss: 0.5460 - categorical_accuracy: 0.7696 - val_loss: 3.5217 - val_categorical_accuracy: 0.3750 - 438ms/epoch - 14ms/step\n",
      "Epoch 113/150\n",
      "32/32 - 0s - loss: 0.5083 - categorical_accuracy: 0.7746 - val_loss: 3.7953 - val_categorical_accuracy: 0.3981 - 436ms/epoch - 14ms/step\n",
      "Epoch 114/150\n",
      "32/32 - 0s - loss: 0.4737 - categorical_accuracy: 0.7875 - val_loss: 3.7971 - val_categorical_accuracy: 0.4120 - 440ms/epoch - 14ms/step\n",
      "Epoch 115/150\n",
      "32/32 - 0s - loss: 0.4807 - categorical_accuracy: 0.7815 - val_loss: 3.8597 - val_categorical_accuracy: 0.3819 - 443ms/epoch - 14ms/step\n",
      "Epoch 116/150\n",
      "32/32 - 0s - loss: 0.4783 - categorical_accuracy: 0.7855 - val_loss: 3.8492 - val_categorical_accuracy: 0.3843 - 440ms/epoch - 14ms/step\n",
      "Epoch 117/150\n",
      "32/32 - 0s - loss: 0.4773 - categorical_accuracy: 0.7885 - val_loss: 3.7916 - val_categorical_accuracy: 0.4144 - 435ms/epoch - 14ms/step\n",
      "Epoch 118/150\n",
      "32/32 - 0s - loss: 0.4901 - categorical_accuracy: 0.7835 - val_loss: 4.0227 - val_categorical_accuracy: 0.3843 - 438ms/epoch - 14ms/step\n",
      "Epoch 119/150\n",
      "32/32 - 0s - loss: 0.4746 - categorical_accuracy: 0.7845 - val_loss: 4.1321 - val_categorical_accuracy: 0.3796 - 440ms/epoch - 14ms/step\n",
      "Epoch 120/150\n",
      "32/32 - 0s - loss: 0.5277 - categorical_accuracy: 0.7786 - val_loss: 3.6962 - val_categorical_accuracy: 0.3657 - 441ms/epoch - 14ms/step\n",
      "Epoch 121/150\n",
      "32/32 - 0s - loss: 0.5596 - categorical_accuracy: 0.7666 - val_loss: 3.8953 - val_categorical_accuracy: 0.3588 - 437ms/epoch - 14ms/step\n",
      "Epoch 122/150\n",
      "32/32 - 0s - loss: 0.4937 - categorical_accuracy: 0.7716 - val_loss: 3.8337 - val_categorical_accuracy: 0.3727 - 439ms/epoch - 14ms/step\n",
      "Epoch 123/150\n",
      "32/32 - 0s - loss: 0.4640 - categorical_accuracy: 0.7776 - val_loss: 4.0059 - val_categorical_accuracy: 0.3611 - 438ms/epoch - 14ms/step\n",
      "Epoch 124/150\n",
      "32/32 - 0s - loss: 0.4504 - categorical_accuracy: 0.7934 - val_loss: 3.9120 - val_categorical_accuracy: 0.3819 - 439ms/epoch - 14ms/step\n",
      "Epoch 125/150\n",
      "32/32 - 0s - loss: 0.4686 - categorical_accuracy: 0.7855 - val_loss: 3.9583 - val_categorical_accuracy: 0.3750 - 442ms/epoch - 14ms/step\n",
      "Epoch 126/150\n",
      "32/32 - 0s - loss: 0.4726 - categorical_accuracy: 0.7915 - val_loss: 4.0461 - val_categorical_accuracy: 0.4282 - 441ms/epoch - 14ms/step\n",
      "Epoch 127/150\n",
      "32/32 - 0s - loss: 0.4454 - categorical_accuracy: 0.8073 - val_loss: 4.0432 - val_categorical_accuracy: 0.3819 - 444ms/epoch - 14ms/step\n",
      "Epoch 128/150\n",
      "32/32 - 0s - loss: 0.4665 - categorical_accuracy: 0.7944 - val_loss: 4.1189 - val_categorical_accuracy: 0.4236 - 443ms/epoch - 14ms/step\n",
      "Epoch 129/150\n",
      "32/32 - 0s - loss: 0.4506 - categorical_accuracy: 0.8064 - val_loss: 4.1070 - val_categorical_accuracy: 0.3819 - 440ms/epoch - 14ms/step\n",
      "Epoch 130/150\n",
      "32/32 - 0s - loss: 0.4807 - categorical_accuracy: 0.7925 - val_loss: 4.0476 - val_categorical_accuracy: 0.3935 - 444ms/epoch - 14ms/step\n",
      "Epoch 131/150\n",
      "32/32 - 0s - loss: 0.4342 - categorical_accuracy: 0.8044 - val_loss: 4.0659 - val_categorical_accuracy: 0.3796 - 441ms/epoch - 14ms/step\n",
      "Epoch 132/150\n",
      "32/32 - 0s - loss: 0.4744 - categorical_accuracy: 0.7716 - val_loss: 3.9755 - val_categorical_accuracy: 0.4190 - 440ms/epoch - 14ms/step\n",
      "Epoch 133/150\n",
      "32/32 - 0s - loss: 0.4178 - categorical_accuracy: 0.8123 - val_loss: 4.2067 - val_categorical_accuracy: 0.3912 - 436ms/epoch - 14ms/step\n",
      "Epoch 134/150\n",
      "32/32 - 0s - loss: 0.4482 - categorical_accuracy: 0.7974 - val_loss: 4.0941 - val_categorical_accuracy: 0.4259 - 442ms/epoch - 14ms/step\n",
      "Epoch 135/150\n",
      "32/32 - 0s - loss: 0.4363 - categorical_accuracy: 0.8004 - val_loss: 4.2166 - val_categorical_accuracy: 0.3704 - 440ms/epoch - 14ms/step\n",
      "Epoch 136/150\n",
      "32/32 - 0s - loss: 0.4389 - categorical_accuracy: 0.8073 - val_loss: 4.2716 - val_categorical_accuracy: 0.3958 - 443ms/epoch - 14ms/step\n",
      "Epoch 137/150\n",
      "32/32 - 0s - loss: 0.4424 - categorical_accuracy: 0.8034 - val_loss: 4.2272 - val_categorical_accuracy: 0.4005 - 435ms/epoch - 14ms/step\n",
      "Epoch 138/150\n",
      "32/32 - 0s - loss: 0.4062 - categorical_accuracy: 0.8173 - val_loss: 4.5431 - val_categorical_accuracy: 0.4074 - 439ms/epoch - 14ms/step\n",
      "Epoch 139/150\n",
      "32/32 - 0s - loss: 0.4427 - categorical_accuracy: 0.7915 - val_loss: 4.4967 - val_categorical_accuracy: 0.3958 - 439ms/epoch - 14ms/step\n",
      "Epoch 140/150\n",
      "32/32 - 0s - loss: 0.4578 - categorical_accuracy: 0.7865 - val_loss: 4.4937 - val_categorical_accuracy: 0.3866 - 436ms/epoch - 14ms/step\n",
      "Epoch 141/150\n",
      "32/32 - 0s - loss: 0.3936 - categorical_accuracy: 0.8153 - val_loss: 4.4891 - val_categorical_accuracy: 0.3935 - 442ms/epoch - 14ms/step\n",
      "Epoch 142/150\n",
      "32/32 - 0s - loss: 0.3810 - categorical_accuracy: 0.8262 - val_loss: 4.5029 - val_categorical_accuracy: 0.4097 - 445ms/epoch - 14ms/step\n",
      "Epoch 143/150\n",
      "32/32 - 0s - loss: 0.3855 - categorical_accuracy: 0.8262 - val_loss: 4.6570 - val_categorical_accuracy: 0.3588 - 466ms/epoch - 15ms/step\n",
      "Epoch 144/150\n",
      "32/32 - 0s - loss: 0.3854 - categorical_accuracy: 0.8133 - val_loss: 4.6574 - val_categorical_accuracy: 0.3681 - 440ms/epoch - 14ms/step\n",
      "Epoch 145/150\n",
      "32/32 - 0s - loss: 0.4567 - categorical_accuracy: 0.7885 - val_loss: 4.5908 - val_categorical_accuracy: 0.3819 - 451ms/epoch - 14ms/step\n",
      "Epoch 146/150\n",
      "32/32 - 0s - loss: 0.4275 - categorical_accuracy: 0.7994 - val_loss: 4.6936 - val_categorical_accuracy: 0.3843 - 445ms/epoch - 14ms/step\n",
      "Epoch 147/150\n",
      "32/32 - 0s - loss: 0.3965 - categorical_accuracy: 0.8232 - val_loss: 4.6287 - val_categorical_accuracy: 0.3819 - 443ms/epoch - 14ms/step\n",
      "Epoch 148/150\n",
      "32/32 - 0s - loss: 0.4401 - categorical_accuracy: 0.7885 - val_loss: 4.7394 - val_categorical_accuracy: 0.3611 - 441ms/epoch - 14ms/step\n",
      "Epoch 149/150\n",
      "32/32 - 0s - loss: 0.4024 - categorical_accuracy: 0.8044 - val_loss: 4.4268 - val_categorical_accuracy: 0.4259 - 442ms/epoch - 14ms/step\n",
      "Epoch 150/150\n",
      "32/32 - 0s - loss: 0.3980 - categorical_accuracy: 0.8143 - val_loss: 4.5063 - val_categorical_accuracy: 0.4074 - 446ms/epoch - 14ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n",
      "[[  2   3   0   5   0   4   0   0   0]\n",
      " [  7 117   7  10   2  27   2   8   9]\n",
      " [  0   9   9   7   1   1   4   3   1]\n",
      " [  4   7   8  16   2   0   7   4   4]\n",
      " [  1   1   0   0   1   1   5   3   3]\n",
      " [  2   7   1   1   0   2   0   0   1]\n",
      " [  3   5   4   3   1   2  12   9   4]\n",
      " [  1   4   1   5   2   1   9   7   6]\n",
      " [  3   8   1   5   0   0   5   2  10]]\n",
      ">#3: 40.741\n",
      "[38.657405972480774, 35.87962985038757, 40.74074029922485]\n",
      "Accuracy: 38.426% (+/-1.991)\n"
     ]
    }
   ],
   "source": [
    "# cnn model\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "\treturn dataframe.values\n",
    "\n",
    "# load a list of files and return as a 3d numpy array\n",
    "def load_group(filenames, prefix=''):\n",
    "\tloaded = list()\n",
    "\tfor name in filenames:\n",
    "\t\tdata = load_file(prefix + name)\n",
    "\t\tloaded.append(data)\n",
    "\t# stack group so that features are the 3rd dimension\n",
    "\tloaded = dstack(loaded)\n",
    "\treturn loaded\n",
    "\n",
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "\tfilepath = prefix + group + '/Inertial Signals/'\n",
    "\t# load all 9 files as a single array\n",
    "\tfilenames = list()\n",
    "\t# total acceleration\n",
    "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "\t# body acceleration\n",
    "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "\t# body gyroscope\n",
    "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "\t# load input data\n",
    "\tX = load_group(filenames, filepath)\n",
    "\t# load class output\n",
    "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "\treturn X, y\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "\n",
    "    version = '3'\n",
    "\n",
    "    if version == '1':\n",
    "        # load all train\n",
    "        trainX, trainy = load_dataset_group('train', prefix + 'HARDataset/')\n",
    "        trainX = trainX[:,:,0:1]\n",
    "        print(trainX.shape, trainy.shape)\n",
    "        # load all test\n",
    "        testX, testy = load_dataset_group('test', prefix + 'HARDataset/')\n",
    "        testX = testX[:,:,0:1]\n",
    "        print(testX.shape, testy.shape)\n",
    "        # zero-offset class values\n",
    "        trainy = trainy - 1\n",
    "        testy = testy - 1\n",
    "        # one hot encode y\n",
    "        trainy = to_categorical(trainy)\n",
    "        testy = to_categorical(testy)\n",
    "        print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "\t\n",
    "    elif version == '2':\n",
    "        # Create a dataset to test cnn on.\n",
    "        X_variant1 = np.cos(np.arange(4, 9, 5e-3))\n",
    "        X_variant1 = np.tile(X_variant1, (350, 1))\n",
    "        X_variant1 = X_variant1 + np.random.normal(0, 0.9, X_variant1.shape)\n",
    "        X_variant1a = np.sin(np.arange(0, 25, 0.025))\n",
    "        X_variant1a = np.tile(X_variant1a, (150, 1))\n",
    "        X_variant1a = X_variant1a + np.random.normal(0, 0.5, X_variant1a.shape)\n",
    "        X_variant1 = np.concatenate((X_variant1, X_variant1a), axis=0)\n",
    "\n",
    "        X_variant2 = np.cos(np.arange(4, 9, 5e-3))\n",
    "        X_variant2 = np.tile(X_variant2, (500, 1))\n",
    "        X_variant2 = X_variant2 + np.random.normal(0, 0.9, X_variant2.shape)\n",
    "\n",
    "        # Create a third class of data that is of a different fuction\n",
    "        X_variant3 = np.tan(np.arange(0, 20, 0.02))\n",
    "        X_variant3 = np.tile(X_variant3, (500, 1))\n",
    "        X_variant3 = X_variant3 + np.random.normal(0, 0.9, X_variant3.shape)\n",
    "\n",
    "        X_variant = np.concatenate((X_variant1, X_variant2, X_variant3), axis=0)\n",
    "        print(X_variant.shape)\n",
    "        # When reshaping each of the values in the last dimension should be in an array\n",
    "        X_variant = X_variant.reshape(-1, 1000, 1)\n",
    "        y = np.zeros((X_variant.shape[0], 3))\n",
    "        y[0:500, 0] = 1\n",
    "        y[500:1000, 1] = 1\n",
    "        y[1000:, 2] = 1\n",
    "\n",
    "        # Train, test, split.\n",
    "        trainX, testX, trainy, testy = train_test_split(X_variant, y, test_size=0.3, stratify=y, random_state=1)    \n",
    "        print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "\t\n",
    "    elif version == '3':\n",
    "        X_variant = X_ghist\n",
    "        X_variant = X_variant.reshape(-1, 1000, 1)\n",
    "        # print(X_variant[0])\n",
    "\n",
    "        # Get the labels as names\n",
    "        y_names = dataset[label_scheme].to_numpy()\n",
    "        # Encode the labels\n",
    "        enc = LabelEncoder().fit(y_names)\n",
    "        y_num = enc.transform(y_names)\n",
    "        # One hot encode the labels\n",
    "        y = to_categorical(y_num)\n",
    "\n",
    "        # Train, test, split.\n",
    "        trainX, testX, trainy, testy = train_test_split(X_variant, y, test_size=0.3, stratify=y, random_state=1)\n",
    "        # Normalise the data\n",
    "        mean = np.mean(trainX)\n",
    "        std = np.std(trainX)\n",
    "        trainX = (trainX - mean) / std\n",
    "        testX = (testX - mean) / std\n",
    "\n",
    "        print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "\n",
    "    return trainX, trainy, testX, testy\n",
    "\n",
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 2, 150, 32\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    # model = Sequential()\n",
    "    # model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    # model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    # model.add(Dropout(0.5))\n",
    "    # model.add(MaxPooling1D(pool_size=2))\n",
    "    # model.add(Flatten())\n",
    "    # model.add(Dense(100, activation='relu'))\n",
    "    # model.add(Dense(n_outputs, activation='softmax'))\n",
    "    # model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "\n",
    "    inputs = keras.Input(shape=(n_timesteps,n_features))\n",
    "    # x = layers.BatchNormalization()(inputs)\n",
    "    x = layers.Conv1D(filters=64, kernel_size=10, activation=\"ReLU\", padding='valid')(inputs)\n",
    "    # x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(filters=64, kernel_size=10, activation=\"ReLU\", padding='valid')(inputs)\n",
    "    # x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(filters=64, kernel_size=10, activation=\"ReLU\", padding='valid')(inputs)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(100, activation=\"ReLU\", kernel_regularizer=regularizers.l1_l2(l1=0.00, l2=0.00))(x)\n",
    "    x = layers.Dense(100, activation=\"ReLU\", kernel_regularizer=regularizers.l1_l2(l1=0.00, l2=0.00))(x)\n",
    "    outputs = layers.Dense(9, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"categorical_accuracy\"])\n",
    "    \n",
    "    # Balance the classes\n",
    "    y_train_labels = np.argmax(trainy, axis=1)\n",
    "    class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train_labels), y=y_train_labels)\n",
    "    class_weights_dict = dict(zip(np.unique(y_train_labels), class_weights))\n",
    "\n",
    "    model.fit(trainX, trainy, validation_data=(testX,testy),epochs=epochs, class_weight=class_weights_dict , batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    preds = model.predict(testX)\n",
    "    cm = confusion_matrix(np.argmax(testy, axis=1), np.argmax(preds, axis=1))\n",
    "    print(cm)\n",
    "    return accuracy\n",
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "\tprint(scores)\n",
    "\tm, s = mean(scores), std(scores)\n",
    "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
    "\n",
    "# run an experiment\n",
    "def run_experiment(repeats=3):\n",
    "\t# load data\n",
    "\ttrainX, trainy, testX, testy = load_dataset()\n",
    "\t# repeat experiment\n",
    "\tscores = list()\n",
    "\tfor r in range(repeats):\n",
    "\t\tscore = evaluate_model(trainX, trainy, testX, testy)\n",
    "\t\tscore = score * 100.0\n",
    "\t\tprint('>#%d: %.3f' % (r+1, score))\n",
    "\t\tscores.append(score)\n",
    "\t# summarize results\n",
    "\tsummarize_results(scores)\n",
    "\n",
    "# run the experiment\n",
    "run_experiment()\n",
    "# X_train, y_train, X_test, y_test = load_dataset()\n",
    "# from matplotlib import pyplot as plt\n",
    "# # print(X_train[20])\n",
    "# set = X_train\n",
    "# sety = y_train\n",
    "# show = np.random.randint(0, set.shape[0])\n",
    "# print(show)\n",
    "# plt.plot(set[show], '.')\n",
    "# plt.gca().invert_yaxis()\n",
    "# print(sety[show])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
